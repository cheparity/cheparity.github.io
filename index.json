[{"content":"","date":"25 November 2025","externalUrl":null,"permalink":"/","section":"Niyuta's Blog","summary":"","title":"Niyuta's Blog","type":"page"},{"content":"","date":"25 November 2025","externalUrl":null,"permalink":"/posts/","section":"Posts","summary":"","title":"Posts","type":"posts"},{"content":" Torch DDP # 记一下分布式训练的要点。\nDataParallel # 首先是要搞清楚 DataParallel vs DistributedDataParallel。\nNote DP 是最简单的多卡方式，但是会一卡猛干，多卡围观，只有一个卡的利用率能到 100%；DDP 所有卡利用率都能拉满。能 DDP 就别 DP。\n这俩首先导入方式不同：\nfrom torch.nn import DataParallel as DP from torch.nn.parallel import DistributedDataParallel as DDP torch 官方说要我们尽可能使用 DistributedDataParallel Getting Started with Distributed Data Parallel — PyTorch Tutorials 2.9.0+cu128 documentation\n大意是，DP 是单进程多线程的单机运行，而 DDP 是多进程，支持单机和多机运行。由于 GIL 的存在，线程间通信需要花费额外开销，所以在单机上 DP 也没有 DDP 快。\n除此之外，DP 是 data parallel，每个 GPU 各自用一个完整模型副本跑平均分过的 batch 数据，只在最后把梯度聚合。而 DDP 是 model parallel，会把同一个前向/反向图切开，让模型不同权重切片跑在不同 GPU 上，所以更快。\n但是 DataParallel 它好写啊！基本上啥也不用改，只需要：\nnum_gpus = torch.cuda.device_count() if num_gpus \u0026gt; 1: print(f\u0026#34;🖥️ Using {num_gpus} GPUs with DataParallel\u0026#34;) model = nn.DataParallel(model) model = model.to(DEVICE) # 原先是cuda:0的话，现在依然是。这个是指主模型的位置 DistributedDataParallel 写法 # 记录了一个比较好的 Single-GPU to DDP 回答。但是！！你都写 DDP 的逻辑了，就不要再写 DP 了。DDP 是肯定优于 DP 的。\n所以重新整理一下。这个初始化顺序还是挺麻烦的。\nimport os, torch, torch.distributed as dist from torch.nn.parallel import DistributedDataParallel as DDP # 1. 先读环境变量 LOCAL_RANK = int(os.environ.get(\u0026#34;LOCAL_RANK\u0026#34;, 0)) WORLD_SIZE = int(os.environ.get(\u0026#34;WORLD_SIZE\u0026#34;, 1)) IS_DDP = WORLD_SIZE \u0026gt; 1 # 2. 初始化进程组（init DDP 必须最先做） if torch.cuda.is_available(): if is DDP and not dist.is_initialized(): dist.init_process_group(backend=\u0026#34;nccl\u0026#34;) torch.cuda.set_device(LOCAL_RANK) # 让当前进程只看对应卡 DEVICE = torch.device(f\u0026#34;cuda:{LOCAL_RANK}\u0026#34;) elif torch.backends.mps.is_available(): DEVICE = torch.device(\u0026#34;mps\u0026#34;) else: DEVICE = torch.device(\u0026#34;cpu\u0026#34;) print(f\u0026#34;🖥️ Using device: {DEVICE}, DDP: {IS_DDP}, Local Rank: {LOCAL_RANK}, World Size: {WORLD_SIZE}\u0026#34;) # 3. 建模型 → 送到正确设备 # 一定要先建模型，然后把模型放到GPU，最后再用DDP包裹 # 否则会出一个经典bug，说模型参数在CPU上 model = MyNetwork() model = model.to(DEVICE) # 4. 再包 DDP（仅 DDP 时） if IS_DDP: model = DDP(model, device_ids=[LOCAL_RANK], output_device=LOCAL_RANK) 这里坑很多。下面说了一个坑，模型经过 DP 或 DDP 包裹后，会被放进 model.module 里。\n如果写的顺序弄反成先包 DDP 再 model.to(DEVICE)，那么两张卡上的进程都把模型先放到了 cuda:0，然后才试图把它挪到 cuda:1，会触发 ValueError: device_ids [1] but got module parameters on cpu / cuda:0\n为什么要把 elif torch.cuda.is_available() 分出来写 cuda，而不是统一写成 cuda:0 也是有讲究的。单卡训练时写 cuda 可以自动适配空闲 GPU，万一主机的 cuda:0 忙碌，就可以自动向后顺延分配。而硬编码会报错。\n最后要调整 DataLoader\ntrain_ds = YourDataset() if IS_DDP: # num_replicas=WORLD_SIZE, rank=LOCAL_RANK， DistributedSampler 会默认读，不需要再传 train_sampler = torch.utils.data.distributed.DistributedSampler( train_ds, shuffle=True, drop_last=True # 可避免总 batch 数不一致 ) train_loader = DataLoader( train_ds, batch_size=BATCH_SIZE, # DDP 时总 batch = per_gpu_batchsize * WORLD_SIZE sampler=train_sampler, num_workers=4, pin_memory=True ) else: train_loader = DataLoader( train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, pin_memory=True ) # 训练循环里要 set_epoch def run_training(): for epoch in range(start_epoch, total_epochs): if IS_DDP: train_loader.sampler.set_epoch(epoch) # 保证不同 epoch 打乱顺序不同 model.train() ... try: run_training() finally: if IS_DDP: dist.destroy_process_group() 另外，代码中的其他逻辑（比如 print，保存模型，等等）会在每个 GPU 上执行一遍。应该限制在 LOCAL_RANK==0 的机子上执行\nif not IS_DDP or LOCAL_RANK == 0: torch.save(module.state_dict(), MODEL_SAVE_PATH) # print(f\u0026#34;💾 Model weights saved to {MODEL_SAVE_PATH}\u0026#34;) 以及比如模型保存之前、解冻参数继续训练等关键同步部分一定要用 dist.barrier() 进行同步！！\n概念解析 # World Size # 整个分布式训练集群里进程 Process 的总数。通常 GPU 和进程一一对应。例如，4 台机子，每个机子 8 卡，World Size 就是 32。\nRank # 进程标识符。分为两种。\n第一种 Global Rank 范围从 0 到 World Size - 1。它是整个分布式训练环境中的绝对唯一 ID。这是最常说的 Rank。\n第二种 Local Rank 范围从 0 到 某台机器上的 GPU 数量 - 1。它是当前机器（节点）内的相对 ID。它用于识别当前进程使用的是本机器上的哪一块 GPU。例如，本地 Rank 0 总是使用机器上的第一块 GPU。\n😵‍💫踩坑记 # Model 找不到模块 # 比如在模型中定义了一个子模块：\nclass Network(nn.Module): def __init__(self): super().__init__() self.sub_det = SimiDetBranch(nb_pools=nb_pools) 然后在训练/推理的时候：\ndef set_requires_grad(module, requires_grad): \u0026#34;\u0026#34;\u0026#34;Set requires_grad attribute for all parameters in a module.\u0026#34;\u0026#34;\u0026#34; # model will move to model.module after DDP for param in module.parameters(): param.requires_grad = requires_grad model = Network() model = DDP(model) set_requires_grad(model.sub_det, True) # ERROR # 或者在推理时 output = model.sub_det(x) # ERROR # 或者在保存时 torch.save(model.state_dict()) # ERROR 会报错找不到 sub_det。\n这是因为 DP 和 DDP 之后，model 的网络结构会被移动到 model.module 里，所以应该 model.module.sub_det。或者写一个 unwrap_model 函数，在上面的场景中替换为 unwrap_model(model)\ndef unwrap_model(model): return model.module if isinstance(model, (DP, DDP)) else model ","date":"25 November 2025","externalUrl":null,"permalink":"/posts/ai/engineer/torch-ddp/","section":"Posts","summary":"","title":"Torch DDP","type":"posts"},{"content":" 贝叶斯网络 # 基本概念 # 贝叶斯网络是一种概率图模型。我觉得没啥讲的，貝氏網路 - 维基百科，自由的百科全书 看下 wiki 就行。简言之，就是一个事件发生受到多种条件概率的影响，而构建的一种概率图模型。\n贝叶斯网是一个有向无环图，其中节点代表随机变量，节点间的边代表变量之间的直接依赖关系，每个节点都附有一个概率分布，根节点 $X$ 所附的是它的边缘分布 $P(X)$，而非根节点 $X$ 所附的是条件概率分布 $P(X|\\pi(X))$，其中 $\\pi(X)$ 指的 $X$ 的祖先节点 $Parent(X)$。\n举例子：下雨会影响洒水车是否工作（显然下雨了就不用工作了），而下雨和洒水车都会影响草地是否湿润。如果 $A$ 事件有概率 $P(B|A)$ 影响 $B$ 事件，就在贝叶斯网络中用 $A\\to B$。这个例子中：\n那么：\n$$ P(Grass\\ wet,Sprinkler, Rain)=P(Rain)P(Sprinkler|Rain)P(Grass\\ Wet)P(Sprinkler)P(Rain) $$也即：利用变量间的条件独立关系可以将联合分布分解成多个复杂度较低的概率分布，从而降低模型表达的复杂度，提高推理效率。\n再举例子：\n求联合概率就是：\n$$ P(S,B,C,D)=P(S)P(C|S)P(B|C,S)P(D|B,C) $$ 贝叶斯网络的三种结构 # Chain 链式结构 # $$ A \\to B \\to C $$最简单的一种结构，直接导出马尔科夫链的性质。事件 $A$ 导致事件 $B$，事件 $B$ 又导致事件 $C$。\n性质：观测阻断。即，观测到 $B$ 则阻断 $A$ 和 $C$ 的连接，$A$ 和 $C$ 变得独立。\n如果不观测 $B$： $A$ 和 $C$ 是相关的。因为 $A$ 变动会影响 $B$，进而影响 $C$。信息流通是畅通的。 如果观测到 $B$（$B$ 已知）： $A$ 和 $C$ 变得条件独立（$A \\perp C \\mid B$）。既然 $C$ 的状态完全取决于 $B$，那么一旦我们知道了 $B$ 的确切结果，$A$ 到底发生了什么对 $C$ 来说就不重要了。路径被 $B$ “阻断”了。 下雨 ($A$) $\\to$ 地面湿 ($B$) $\\to$ 容易滑倒 ($C$) 如果我们知道地面是湿的（$B$ 被观测），那么不管这水是因为下雨（$A$）还是洒水车造成的，“容易滑倒”的概率只取决于地面湿不湿。此时，$A$ 对 $C$ 没有额外的信息价值。\n证明：\n$$ \\begin{align} P(A,C|B)\u0026=\\frac{P(A,B,C)}{P(B)}\\\\\u0026=\\frac{P(A)P(B|A)P(C|B)}{P(B)}\\\\\u0026=\\frac{P(A,B)P(C|B)}{P(B)}\\\\\u0026=P(A|B)P(C|B) \\end{align} $$即在中间的变量已知的情况下，后一个变量和之前的所有变量都无关，只取决前一个变量。这是马尔科夫链的性质啊！\nFork 叉形结构 # $$ B \\leftarrow A \\to C $$事件 $A$ 是事件 $B$ 和事件 $C$ 的共同原因。\n性质：观测阻断。观测到 $A$ 则阻断 $B$ 和 $C$。\n如果不观测 $A$： $B$ 和 $C$ 是相关的。因为它们受同一个因素影响。通常如果 $B$ 发生了，我们可以推测 $A$ 可能发生了，进而推测 $C$ 也可能发生。 如果观测到 $A$（$A$ 已知）：$B$ 和 $C$ 变得条件独立（$B \\perp C \\mid A$）。 $$ \\begin{align} P(B,C|A)\u0026=\\frac{P(A,B,C)}{P(A)} \\\\ \u0026=\\frac{P(A)P(B|A)P(C|A)}{P(A)} \\\\ \u0026=P(B|A)P(C|A) \\end{align} $$ 年龄 ($A$) $\\to$ 鞋码大小 ($B$)；年龄 ($A$) $\\to$ 识字量 ($C$) 在小学生群体中，鞋码越大的人，通常识字量也越多（因为年龄大了）。但如果我们固定住年龄（比如只看 7 岁的孩子），那么鞋码和识字量之间就不再有相关性了。\nImmorality 非道德结构 # 可以记成对撞机结构。\n$$ A \\to C \\leftarrow B $$事件 $A$ 和事件 $B$ 共同导致了事件 $C$。这个的性质也和前两者不一样。\n性质：观测激活。观测到 $C$ 则 $A$ 和 $B$ 就会有联系。\n如果不观测 $C$： $A$ 和 $B$ 是独立的。原因 $A$ 和原因 $B$ 互不相干，各自发生。 如果观测到 $C$（$C$ 已知）： $A$ 和 $B$ 变得相关。既然 $C$ 发生了，如果 $A$ 是造成 $C$ 的原因，那么 $B$ 是原因的可能性就会降低。这被称为 \u0026ldquo;Explaining Away\u0026rdquo;（消除解释）。 编程水平 ($A$) + 运气好 ($B$) $\\to$ 通过面试 ($C$) 在一般人群中，编程水平和运气通常没有必然联系（$A \\perp B$）。但如果我们知道某人通过了面试（$C$ 被观测），且后来发现他编程水平极差（$A$ 很低），那么我们可以推断他的运气一定非常好（$B$ 很高）。此时，观测结果 $C$ 使得原本独立的 $A$ 和 $B$ 产生了（负）相关性。\n证明（边际独立性）：\n$$ \\begin{align} P(A,B) \u0026= \\sum_{C} P(A,B,C) \\\\ \u0026= \\sum_{C} P(A)P(B)P(C|A,B) \\\\ \u0026= P(A)P(B) \\sum_{C} P(C|A,B) \\\\ \u0026= P(A)P(B) \\cdot 1 \\\\ \u0026= P(A)P(B) \\end{align} $$即在未观测中间变量的情况下，两个父节点是独立的。一旦观测 $C$，联合概率变为 $P(A,B|C) \\propto P(A)P(B)P(C|A,B)$，由于 $P(C|A,B)$ 这一项将 $A$ 和 $B$ 耦合在一起，通常无法分解，从而阻断了独立性（即路径被激活了）。\n马尔可夫毯 Markov Blanket # 马尔可夫毯包括该节点的父节点、子节点以及子节点的父节点。翻译成人话就是，假设 $A$ 是我们观测的变量，那么：\n谁指向 $A$，即 $A$ 的父节点。 $A$ 指向谁，即 $A$ 的子节点，标记为 $B$。 谁指向 $B$，即子节点的父节点。 这三类都应该包含在 Markov Blanket 中。\n概率图中，马尔科夫毯就是一块毯子，为了使其中一个节点和其它节点条件独立，我们用毯子盖住这个节点周围与其相关的节点，那么毯子外面的节点和这个节点就条件独立了。\n似乎不太重要。不写了😏。\n从贝叶斯网络走向因果推断 # 这一块儿选讲，不考，但一般不考的都是有意思的。\n问题引入 # 2011 年图灵奖得主、因果科学之父 Judea Pearl 曾提出著名的“因果阶梯”论（Pearl Causal Hierarchy，PCH）。他认为，因果推断有三个层级，最低的第一层级是相关（association），涉及的是预测，而不涉及因果关系，只讨论变量之间的关联，比如公鸡打鸣与日出之间的相关关系。\n第一层（关联 association）： 观察（Seeing）。贝叶斯网主要处于这一层。 第二层（干预 intervention）： 行动（Doing）。如果不这么做会怎样？（因果推断） 第三层（反事实 Counterfactuals）： 想象（Imagining）。如果当时我没那么做，现在会怎样？（人类智能的高级形式） 我们前面讲的 bayes network 停留在第一层。调查统计发现，喝咖啡 （事件 $A$）的人似乎更容易焦虑（事件 $C$），但是有人辩解说：是因为喝咖啡的人本身压力大（事件 $B$），压力大的人往往睡眠不足，进而更倾向于喝咖啡，压力大的人也更容易焦虑。\n前一种因果图：$A \\to C$ 后一种因果图：$A \\leftarrow B \\to C$。这是一种混淆结构，$B$ 压力大是共同原因，连接了喝咖啡 $A$ 和焦虑 $C$。 前面提到的 fork 叉形结构中说，如果不观测 $B$，那么 $A$ 和 $C$ 是相关的。在这个结构中，喝咖啡本身不是焦虑的原因（即 $A \\to C$ 不存在） 显然我们观察到了抽烟和患肺病有相关的关系。那么喝咖啡究竟会不会让人焦虑呢？\nDo 算子 # do 算子（由 Judea Pearl 引入）是因果推断中的核心概念，它将观察和干预在数学上严格区分开来。\n观察（Conditioning）： $P(Y | X=x)$ 含义：在自然地观察到 $X$ 取值为 $x$ 的人群中，$Y$ 的概率分布。 问题： 这种观察到的关系包含了 $X \\to Y$ 的真实因果效应，以及任何连接 $X$ 和 $Y$ 的后门路径（即混淆因素引起的虚假关联）。 干预（Intervening）：$P(Y | do(X=x))$ 含义：我们强制性地将所有人的 $X$ 值都设置为 $x$ 之后，$Y$ 的概率分布。 效果： 这个操作在因果图上切断了所有指向 $X$ 的箭头（即 $X$ 的所有原因），从而消除了所有由混淆因素产生的后门路径。 后门调整公式 $\\text{因果效应} = P(C|do(A)) = \\sum_{b} P(C|A, B=b) P(B=b)$\n为了计算咖啡对引起焦虑的真实的因果效应，我们要把压力的后门路径消除：\n$$ P(\\text{焦虑} | do(\\text{咖啡})) = \\sum_{\\text{压力}} P(\\text{焦虑} | \\text{咖啡}, \\text{压力}) P(\\text{压力}) $$这个公式的含义是，我首先分层计算 $P(C|A, B)$。将人群按照压力水平 $B$ 进行分层（例如：“压力低”组、$B_1$；“压力高”组、$B_2$），在压力相同的每一层中，我们再比较“喝咖啡的人”和“不喝咖啡的人”的焦虑差异。在 $B_1$ 组（低压力）中，如果 $A \\to C$ 的效应很小甚至为零，说明咖啡可能不是焦虑的主要原因。在 $B_2$ 组（高压力）中，如果 $A \\to C$ 的效应依然存在，说明咖啡因本身可能确实会增加焦虑。通过这种分层，我们控制了压力 $B$ 的影响。\n最后，我们根据压力 $B$ 在总人口中的真实分布 $P(\\text{压力})$，对每个分层的结果进行加权求和，得到一个适用于整体人群的、去除了压力混淆的平均因果效应 $P(C | do(A))$。\n","date":"22 November 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E8%B4%9D%E5%8F%B6%E6%96%AF%E7%BD%91%E7%BB%9C/","section":"Posts","summary":"","title":"贝叶斯网络","type":"posts"},{"content":" Bayes 估计 # 在笛卡尔的哲学世界——先验主体性里，他认为无需经验或先于经验获得的认知为先验知识，需要通过经验调整的知识成为后验知识。从原因到结果的论证称为“先验的”，从结果到原因的论证称为“后验的”。相信前者的人被称为理性主义者，相信后者的人被称为经验主义者。\n这章内容叫做参数估计：点估计，因此指的是对模型的参数 $\\theta$ 的估计。以机器学习为例，我们假设数据分布可以用一个 $\\pi(\\theta)$ 的模型（比如是一个正态分布模型）去描述，那么如何估计正态分布的参数 $\\theta$——即 $\\mu$ 和 $\\sigma^{2}$ 呢？之前的内容中，矩估计 说可以统计样本的矩统计量来代替正态分布模型的 $\\mu$ 和 $\\sigma^{2}$，极大似然估计 则说让样本出现尽可能更合理地满足参数…\n而这次是贝叶斯估计。贝叶斯说，人们心中对 $\\theta$ 的分布有一个原初的信念，这个信念叫做先验分布 $\\pi(\\theta)$。比如上面的例子里我们完全可以先入为主地猜 $\\mu=0$。然后，在我们收集到足够多数据 $\\mathbf{x}$ 的时候，再去利用数据调整我们的先验分布 $\\pi(\\theta)$，使之成为后验分布 $P(\\theta|X)$。这个过程就叫贝叶斯估计。\n贝叶斯公式 $P(B|A)=\\frac{P(A|B)P(B)}{P(A)}$\n由此推导出对参数 $\\theta$ 的估计：\n$P(\\theta|X)=\\frac{P(X|\\theta)\\pi(\\theta)}{P(X)}$\n其中 $\\pi(\\theta)$ 被称为 $\\theta$ 的先验概率。\n最小均方误差下的贝叶斯估计 # 我们估计出的 $\\hat{\\theta}$ 与真实值 $\\theta$ 一般有偏差。我们对 $\\theta$ 定义一个损失函数 $\\mathcal{L}(\\hat{\\theta},\\theta)$ ，在所有 $\\theta \\in \\Theta$ 空间上，总体风险：\n$$ R(\\hat{\\theta}|x)=\\int_{\\Theta}\\mathcal{L}(\\hat{\\theta},\\theta)p(\\theta|x)d\\theta $$我们应该找到使这个风险在所有样本 $X$ 上最小的 $\\hat{\\theta}=argminR(\\hat{\\theta}|x)$。我们有结论：\n最小均方误差下的贝叶斯参数估计 当总体样本 $X$ 数量有限，$\\mathcal{L}(\\hat{\\theta},\\theta)=||\\hat{\\theta}-\\theta||^{2}$ 为均方误差损失时， $\\theta^\\star=\\mathbb E(\\theta|X)$\n0-1 损失下的贝叶斯参数估计 除此之外作业中还提到 0-1 损失，此时参数 $\\theta$ 的贝叶斯估是 MAP(Maximum A Posteriori)，即 $\\hat{\\theta}=\\arg\\min\\limits_{\\theta} p(\\theta|X)$\nMSE 贝叶斯估计基本步骤 我们估计的是参数 $\\theta$，基本思路是用数据修正 $\\theta$ 的估计值。因此：\n确定参数 $\\theta$ 的先验分布 $p(\\theta)$。题目中可能会直接告诉你 由样本集 $X = {x_1, x_2, …, x_N}$ 求出样本联合分布 $p(X|\\theta)$：$p(X|\\theta) = \\prod_{n=1}^{N} p(x_n|\\theta)$ 利用贝叶斯公式，求 $\\theta$ 的后验分布：$p(\\theta|X) = \\frac{p(X|\\theta)p(\\theta)}{\\int_{\\Theta} p(X|\\theta)p(\\theta)d\\theta}$ 平方损失下，求出贝叶斯估计为参数的后验分布，对参数全域的积分：$\\theta^* = \\int_{\\Theta} \\theta p(\\theta|X)d\\theta$ 共轭贝叶斯 # 以上说的理论已经把贝叶斯估计的方法论阐释得差不多了，但是从机器学习的角度出发，还略有不足。我们知道机器学习是一个不断用数据迭代、修正模型的方法，它天生就和贝叶斯有关。而这个过程中，模型在用数据修正前后显然需要保持不变。换句话说，后验分布和先验分布，需要是同一个分布族。这种性质就叫做共轭先验。这一块在 PRML 的第一章还是第二章有很深刻的涉及。\n从这个意义上来讲，我们在用数据修正贝叶斯模型时，只需要关注分子而无需考虑分母，因为分母只是归一化的常数且与 $\\theta$ 无关，并不会改变 $\\theta$ 分布的特征。如果后验概率是离散的，求后验概率时，也可以先求后验概率每个值的未归一化后验权重，再归一化。\n","date":"22 November 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E7%82%B9%E4%BC%B0%E8%AE%A1/%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/","section":"Posts","summary":"","title":"贝叶斯估计","type":"posts"},{"content":" 一致最大功效检验 UMP # 一致最大功效检验 Uniform Most Powerful Test 是指在所有满足相同显著性水平 $\\alpha$ 的检验中，对于备择假设空间 $H_1$ 中的每一个参数值，其功效都是最高的那个检验。\n一致最大功效检验 UMP 定义 $H_{0}: \\theta \\in \\Theta_{0} \\ \\text{vs} \\ H_{1}:\\theta \\in \\Theta_{1}$，设 $\\phi^\\star(x)$ 是水平 $\\alpha$ 的检验中，对任一水平 $\\alpha$ 的检验 $\\phi$，都有： $\\beta_{\\theta}(\\phi^{\\star}(x)) \\geq \\beta_{\\theta}(\\phi(x))$ 对所有 $\\theta \\in \\Theta_{1}$ 成立。称 $\\phi^\\star(x)$ 是水平 $\\alpha$ 的一致最大功效检验。\n以上定义注意一点：是对所有 $\\theta \\in \\Theta_{1}$ 成立，而不管 $\\theta \\in \\Theta_{0}$ 的部分，因为只有 $\\theta \\in \\Theta_{1}$ 的时候 $\\beta$ 才称为检验的功效 power。\nNeyman-Pearson Lemma # 检验原理的核心是：控制犯第一类错误的概率在给定的范围 $\\alpha$ 内，寻找检验使得犯第二类错误的概率尽可能小，即检验的势尽可能大。也就是：\n$$ \\text{Power}(\\theta)=P_{\\theta}(\\text{reject\\ }H_{0} | \\theta)=1-\\beta(\\theta), \\theta \\in \\Theta_{1} $$其中 $\\beta(\\theta)$ 为犯第二类错误的概率。\n26.1 - Neyman-Pearson Lemma | STAT 415 在原假设和备择假设都是简单假设的情况下，我们可以判别哪些假设为水平为 $\\alpha$ 的 UMP。\n考虑简单假设 $H_{0}:\\theta=\\theta_0 \\ \\text{vs} \\ H_{1}: \\theta=\\theta_{1}$。如果一个水平为 $\\alpha$ 的检定 $\\phi(x)$ 使得 似然比检验\n$$ \\phi(x) = \\begin{cases} 1 \u0026 \\text{当 } \\frac{\\mathcal{L}(x | \\theta_{1})}{\\mathcal{L}(x | \\theta_{0})} \u003e k \\\\ \\gamma \u0026 \\text{当 } \\frac{\\mathcal{L}(x | \\theta_{1})}{\\mathcal{L}(x | \\theta_{0})} = k \\\\ 0 \u0026 \\text{当 } \\frac{\\mathcal{L}(x | \\theta_{1})}{\\mathcal{L}(x | \\theta_{0})} \u003c k \\end{cases} $$其中 $k$ 和 $\\gamma$ 是由显著性水平 $\\alpha$ 唯一确定的常数，满足 $E_{\\theta}(\\phi(x))=\\alpha$：\n$$ P\\left(\\frac{\\mathcal{L}(X | \\theta_{1})}{\\mathcal{L}(X | \\theta_{0})} \u003e k \\mid \\theta = \\theta_0\\right) + \\gamma \\cdot P\\left(\\frac{\\mathcal{L}(X | \\theta_{1})}{\\mathcal{L}(X | \\theta_{0})} = k \\mid \\theta = \\theta_0\\right) = \\alpha $$那么 $\\phi(x)$ 是一个 UMP 检定。这个结论确保了在 $\\alpha$ 水平上，检验 $\\phi(x)$ 具有最大的功效。\nNote 这么记：出现 $H_{0}$ 的似然越小越拒绝它。出现 $H_{1}$ 的概率超过 $k$ 倍出现 $H_{0}$ 的概率时，就拒绝 $H_{0}$。 一定要是点对点的 $H_{0}: \\theta = \\theta_{0}$ 和 $H_{1}:\\theta = \\theta_{1}$，即原假设和备择假设都是简单假设，都只有一个取值。不能 $H_{1}: \\theta_{1}\u0026gt;\\theta_{0}$。 约束条件一般不用记。它保证了检验的真实水平恰好等于 $\\alpha$ (即 $\\text{Size} = \\alpha$)。 $\\gamma$ (随机化拒绝概率) 用于处理离散分布中，似然比恰好等于 $k$ 时需要精确匹配 $\\alpha$ 的情况。 由于充分统计量可以表征 LRT，以上定理中的 Likelyhood 部分也可以用 $T(x|\\theta_{i}),i=0,1$ 来直接代替。\n1. 核心理论：单调似然比 (MLR) # 如果总体分布属于指数族，其概率密度（或分布律）可以写成：\n$$ p(x, \\theta) = d(\\theta) h(x) \\exp\\{c(\\theta) T(x)\\} $$这里的 $c(\\theta)$ 决定了似然比随统计量 $T(x)$ 变化的方向。\n2. 如何判断拒绝域的方向？ # 口诀 同向大，反向小。\n同向大：如果备择假设 $H_1$ 的方向（$\\theta \u0026gt; \\theta_0$）与 $c(\\theta)$ 的单调性（增）一致，拒绝域就在大的一侧：$T(x) \u0026gt; C$。 反向小：如果方向相反（如 $\\theta \u0026gt; \\theta_0$ 但 $c(\\lambda) = -\\lambda$ 是减函数），拒绝域就在小的一侧：$T(x) \u0026lt; C$。 我们要检验 $H_0: \\theta = \\theta_0$ vs $H_1: \\theta = \\theta_1$。\n根据 Neyman-Pearson 引理，拒绝域的形式由似然比 $\\frac{p(x, \\theta_1)}{p(x, \\theta_0)} \u0026gt; k$ 决定。\n代入指数族公式：\n$$ \\frac{p(x, \\theta_1)}{p(x, \\theta_0)} = \\frac{d(\\theta_1)}{d(\\theta_0)} \\exp\\{ [c(\\theta_1) - c(\\theta_0)] T(x) \\} \u003e k $$取对数后，你会发现拒绝域取决于 $[c(\\theta_1) - c(\\theta_0)] T(x)$ 的符号：\n情况 A：$c(\\theta)$ 是严格单调增函数 如果我们要检验的是右侧 $H_1: \\theta \u0026gt; \\theta_0$： 此时 $\\theta_1 \u0026gt; \\theta_0$，因为 $c(\\theta)$ 增，所以 $c(\\theta_1) - c(\\theta_0) \u0026gt; 0$。 为了让整个式子大于 $k$，我们需要 $T(x)$ 足够大。 结论：拒绝域为 $W = {T(x) \u0026gt; C}$。 如果我们要检验的是左侧 $H_1: \\theta \u0026lt; \\theta_0$： 此时 $\\theta_1 \u0026lt; \\theta_0$，则 $c(\\theta_1) - c(\\theta_0) \u0026lt; 0$。 为了抵消负号让式子大于 $k$，我们需要 $T(x)$ 足够小。 结论：拒绝域为 $W = {T(x) \u0026lt; C}$。 情况 B：$c(\\theta)$ 是严格单调减函数 结论与上述相反。 $H_1: \\theta \u0026gt; \\theta_0 \\implies W = {T(x) \u0026lt; C}$ $H_1: \\theta \u0026lt; \\theta_0 \\implies W = {T(x) \u0026gt; C}$ 定常数找点 # 单边：利用 $P_{\\theta_0}(T(x) \\in W) = \\alpha$ 查表或积分求出 $C$。 双边：利用课件上的方程组： $E_{\\theta_0}[\\phi(x)] = \\alpha$ $E_{\\theta_0}[T(x)\\phi(x)] = \\alpha E_{\\theta_0}[T(x)]$ 如果分布对称，直接让左右两端概率各为 $\\alpha/2$ 即可。 最优势检验 MPT # 最优势检验 (Most Powerful Test, 简称 MPT 检验) 就是在所有满足要求的检验方法中，“抓坏人”能力最强的那一个。\n假设我们要检验 $H_0$（原假设）和 $H_1$（备择假设）：\n约束条件：我们要把“误报率”（第一类错误 $\\alpha$，即把好人当坏人）控制在一个很低的水平（比如 0.05）。 目标：在误报率不超过 $\\alpha$ 的所有检验中，我们要找出一个方法，使得它的召回率（功效 Power，即坏人出现时准确抓到它的概率 $1-\\beta$）达到最大。 这个功效（Power）最大的检验，就叫最优势检验。\n为了理解它，我们需要关注两个核心：\n显著性水平 ($\\alpha$)：这是你的“底线”。就像训练分类器时，你规定 False Positive Rate 不能超过 5%。 功效函数 ($g(\\theta)$)：这是你的“能力”。当真实情况确实是备择假设 $H_1$ 时，你拒绝 $H_0$ 的概率。 最优势检验的准则：\n如果在所有满足 $P(\\text{拒绝 } H_0 | H_0 \\text{ 为真}) \\le \\alpha$ 的检验中，某一个检验 $\\phi^*$ 满足：\n对于 $H_1$ 里的参数，它的 $g(\\theta)$ 是所有检验里最高的。\n那么 $\\phi^*$ 就是最优势 (MP) 的。\n一致最优势检验 UMPT # 在实际中，备择假设往往不是一个点（比如 $H_1: \\theta \u0026gt; \\theta_0$ 包含很多个值）。\n如果一个检验方法，对于 $H_1$ 区域内的每一个可能的 $\\theta$ 值，都能保持“功率最大”，那它就升级为 一致最优势检验 (Uniformly Most Powerful Test, UMPT)。 举个例子。想象你在设计一个垃圾邮件过滤器：\n$H_0$：邮件是正常的。 $H_1$：邮件是垃圾邮件。 限制：你老板要求“正常邮件被误判为垃圾邮件”的概率不能超过 1% ($\\alpha = 0.01$)。 最优势检验：在所有误判率低于 1% 的过滤器中，那个能抓住最多垃圾邮件的算法，就是最优势检验。 ","date":"17 November 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/%E4%B8%80%E8%87%B4%E6%9C%80%E5%A4%A7%E5%8A%9F%E6%95%88%E6%A3%80%E9%AA%8C-ump/","section":"Posts","summary":"","title":"一致最大功效检验 UMP","type":"posts"},{"content":"参考：\n统计推断 (Statistical Inference) 第二版 - George Casella Likelihood Ratio Tests 【Proof-Trivial】统计推断 (George Casella)【台北大学-李孟峰】【中文】_哔哩哔哩_bilibili 似然比检验 # LRT # 【似然比检验 Likelihood Ratio Test】设样本为 $x$，那么 $H_{0}: \\Theta \\in \\Theta_{0}$ 对 $H_{1}: \\Theta \\in \\Theta_{0}^C$ 的似然比检验 (LRT 准则) 定义为原假设空间 $\\Theta_0$ 与全空间 $\\Theta$ 的似然最大值之比：\n$$ \\lambda(x)=\\frac{\\underset{\\theta \\in \\Theta_{0}}{\\sup} \\mathcal{L}(\\theta | x)} {\\underset{\\theta \\in \\Theta}{\\sup} \\mathcal{L}(\\theta|x)} \\leq c $$其中临界值/显著性水平 $c \\in [0, 1]$ ，检验定的拒绝域形式为 ${ x : \\lambda(x)\\leq c }$。\n似然比检验可以用于机器学习，如果我们要比较两个模型谁的参数更优，显然可以比较 $\\mathcal{L}(\\theta_{1};x)$ 和 $\\mathcal{L}(\\theta_{2};x)$ 哪个更大，即哪个 $\\theta$ 能使得模型似然函数更大。Likelihood Ratio Tests 讲得很好，强烈建议看看。\n另，我感觉这个 $\\theta|x$ 的条件概率好像和贝叶斯没什么关系，只是表示同时出现 $\\theta$ 和 $x$ 这俩统计量。\n我们不妨这样理解：如果 $\\Theta_{0}$ 是 $\\Theta$ 的一个子集，分母表示对 $\\theta$ 不加限制得到的似然函数的极大值，分子表示对 $\\theta$ 加以限制，可以让似然函数达到的极大值。考虑两个极端情况，如果分子分母比值为 1，那么意味着最佳的似然函数就在 $\\Theta_{0}$ 区间中取到，自然不该去拒绝 $H_{0}$；而如果比值为 0，即分子为 0，表示 $\\theta \\in \\Theta_{0}$ 区间内根本不可能出现 $x$ 这样的观测数据——我们自然应该拒绝 $H_{0}$。\n这里有一个很有意思的定理，看了书例 8.2.2（正态 LRT）和例 8.2.3（指数分布 LRT）之后，会对此有更深刻的理解。\n正态分布 LRT 的拒绝域最后落脚到了它的充分统计量 $\\bar{x}$ 上：\n$$ {\\mathbf{x}: \\left\\{ |\\bar{x}-\\theta_{0}| \\geq \\sqrt{ -\\frac{2\\log c}{n} } \\right\\}} $$而指数分布 LRT 的拒绝域则落脚到和指数分布的充分统计量——顺序统计量 $x_{(1)}$ 上。那我们似乎观察出 LRT 与充分统计量之间似乎有一定的关系。\n和充分统计量的关系 # 似然比检验和充分统计量的关系 设 $T(X)$ 为 $\\theta$ 的充分统计量，而 $\\lambda^\\star(t)$ 和 $\\lambda(x)$ 分别是依赖于 $T$ 和 $X$ 得到的 LRT，则 $\\lambda^{\\star}(T(X))=\\lambda(x)$。即，LRT 检定的拒绝域可由 $T(X)$ 决定。\n一些二级结论 # 正态分布的检验统计量 Z-Score # 正态分布的检验统计量（也叫 Z-score）：\n$$ Z = \\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}} $$本质上其实是：\n$$ \\text{Z} = \\frac{\\text{观测值} - \\text{假设值}}{\\text{标准误差}} $$一般我们认为当 $Z \u0026gt; c$（c 是临界值） 时拒绝原假设 $H_{0}$。\n无偏检验 # 【无偏检验】对于检验问题 $H_0: \\theta \\in \\Theta_0$ vs $H_1: \\theta \\in \\Theta_1$，若势函数 $g(\\theta)$ 满足：\n$\\sup_{\\theta \\in \\Theta_0} g(\\theta) \\le \\alpha$ $\\inf_{\\theta \\in \\Theta_1} g(\\theta) \\ge \\alpha$ 则该检验是水平为 $\\alpha$ 的无偏检验。\n即判断一个检验为无偏检验需要满足两个核心条件：\n在原假设 $H_0$ 成立时：犯第一类错误的概率（弃真）不超过给定的显著性水平 $\\alpha$。 在备择假设 $H_1$ 成立时：正确拒绝原假设的概率（势）至少要达到 $\\alpha$。 无偏性是一个非常合理的性质。如果一个检验是“有偏”的，意味着在某些备择假设情况下，你正确拒绝原假设的概率竟然比随机误判的概率（$\\alpha$）还要低。这就像一个分类器在处理猫的图片时，识别它是猫的准确率竟然比随机猜还要低，那这个模型（检验）显然是有问题的。\n","date":"10 November 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/%E4%BC%BC%E7%84%B6%E6%AF%94%E6%A3%80%E9%AA%8C/","section":"Posts","summary":"","title":"似然比检验","type":"posts"},{"content":"参考：\n统计推断 (Statistical Inference) 第二版 - George Casella 【Proof-Trivial】统计推断 (George Casella)【台北大学-李孟峰】【中文】_哔哩哔哩_bilibili 假设检验是统计实验的内容，有个著名的故事叫 女士品茶。\n假设检验的评价 # 原假设，备择假设，两类错误 # 假设检验就是，我提出一个原假设/零假设 $H_{0}$，再看有多大可能性给它否掉——否掉的话就接受了原假设互补的假设，我们管它叫备择假设 $H_{1}$。假设检验一般由参数 $\\theta$（或者说统计量）来决定。$\\theta$ 的值域为 $\\Theta$，那在其中接受原假设的参数空间 $\\Theta_{0}$ 记作 $H_{0}:\\theta \\in \\Theta_{0}$，不接受原假设（接受备择假设 $H_{1}$）的参数空间为 $\\Theta_{0}$ 的补集，记为 $H_{1}: \\theta \\in \\Theta_{0}^C$。\n假设检验在检验什么？——在检验参数 $\\theta$。所以后文中，拒绝 $H_{0}$ 与 $\\theta \\in \\Theta_{0}$ 表达同样的意思。\n这个 $\\theta$ 代表了我们的假设，我们要抽样 $X$ 来计算统计量 $\\theta$，以确定 $\\theta$ 是属于 $\\Theta_{0}$ 还是 $\\Theta_{1}$。\n显著性水平 $\\alpha$ # 那什么情况下，我们会去拒绝原假设 $H_{0}$ 呢？例如，一个工厂生产的零件尺寸，合理均值 $\\mu_{0}$ 应该是 5mm，但是这个批次的大小均值 $\\bar{x}$ 到了 10mm，生产工人此时告诉你他生产的零件是正常的，你会相信吗？你应该如何去否定他呢？\n一般来讲，当我们要检验的参数 $\\theta$ 极大地脱离正常水平时就去否定 $H_{0}$。上面的例子中我们可以假设零件尺寸满足正态分布 似然比检验，那么一个合理的直觉是如果 $H_{0}$ 是正确的，那么 $|\\bar{x}-\\mu_{0}|$ 不能太大，对应如果要拒绝 $H_{0}$，那 $|\\bar{x}-\\mu_{0}|$ 的概率就不能太小。用概率的角度写出来即是：\n$$ \\text{拒绝 } H_0 \\iff |Z_{\\text{obs}}| = \\left|\\frac{\\bar{x} - \\mu_0}{\\sigma / \\sqrt{n}}\\right| \u003e Z_{\\alpha/2} $$这个 $\\alpha$ 就叫做显著性水平，通常很小，如取 0.05,0.1，但显然由于它是概率值，故是属于 $(0,1)$ 的。当这个概率大于 $\\alpha$ 时，我们就可以否定 $H_{0}$ 了，此时可以解出参数 $\\theta$（在上面的例子中是 $\\bar{x}$）的拒绝域 $\\Theta_{0}^C$，刚好拒绝的那个点被称为是临界点 $c$。\n然而抽样的运气有好有坏，万一工人生产出的一千个零件，只有这 5 个不好的被你抽中了，那你还拒绝他，这不是纯冤枉人了吗？由此可见，在样本容量 $n$ 有限的情况下，我们是有可能犯错误的。如果我们把拒绝域设为 $R$，那么：\n两类错误 # 两类错误 一类错误 Type I Error：$\\theta \\in \\Theta_{0}$，但是 $x \\in R$，错误地推翻、拒绝了原假设 $\\Theta_{0}$。也叫拒真错误。显然犯一类错误的概率是 $P_{\\theta}(reject \\ H_{0} | H_{0}) = P_{\\theta}(X \\in R)$。\n二类错误 Type II Error：$\\theta \\notin \\Theta_{0}$，但是 $x \\in R^C$，错误地接受了原假设 $\\Theta_{0}$。也叫取伪错误。犯二类错误的概率是 $P_{\\theta}(accept \\ H_{0} | H_{1})=P_{\\theta}(X \\in R^C)=1-P_{\\theta}(X \\in R)$。\n犯这两类错误的概率不可能同时减小，因为其之和为 1（这个需要保证接受域 $R^C$ 为拒绝域 $R$ 的严格补集）。在检验统计量和样本大小均不变的情况下，减少犯其中一类错误的几率，必然会增加犯另一类错误的几率。统计假设一般更倾向于支持原假设，除非我有充足证据，否则我不会去推翻，所以二者不可兼得的情况下我们会尽可能降低一类错误的概率。\n无罪推定 “犯罪嫌疑人”的说法，我们的原假设 $H_{0}:犯罪嫌疑人无罪$，备择假设 $H_{1}:犯罪嫌疑人有罪$。我们想尽可能接受原假设，降低把原假设错误推翻的概率——这个就是尽可能减少一类错误即减少误判有罪。除非我们证据十分强大，我们才会推翻 $H_{0}$。\n功效函数 # 我们想一想：如果我们有一个量表示拒绝原假设的概率，那么它越大，就表示越容易拒绝 $H_{0}$，我们犯一类错误的概率（拒真错误，$H_{0}$ 原本是对的，但是你把它拒了）也就越大；相反地，如果拒绝原假设的概率越小，那么你就越有可能遇见“原假设错了，但是你接受它”的情况，即犯第二类错误（取伪错误）的概率会增大。\n功效函数考察什么情况下会拒绝原假设，那我们就要看拒绝原假设的概率，也就是 $P(reject \\ H_{0} | \\theta)$。\n功效函数：检定力水平 Power Function 设拒绝域为 $R$，抽样为 $X$，则功效函数定义为 $\\beta(\\theta)=P_{\\theta}(X \\in R)$ 亦即：$\\beta(\\theta)=P(reject \\ H_{0} | \\theta)$\n$\\theta$ 显然分两种情况，即原假设对 or 不对：\n$\\theta \\in \\Theta_{0}$，那么 $\\beta(\\theta)=P(reject \\ H_{0} | \\theta \\in \\Theta_{0}) = P(Type \\ I \\ Error)$。我们希望犯一类错误的概率不超过显著性水平 $\\alpha$。 $\\theta \\in \\Theta_{0}^C$，那么 $\\beta(\\theta) = P(reject \\ H_{0} | \\theta \\in \\Theta_{0}^C) = 1 - P(Type \\ II \\ Error)$。要是原假设本身是错，我们肯定希望尽可能推翻它，故这里表现出一种去伪的能力，叫检定力水平 Power，希望它越大越好。 这里参考书例 8.3.2 会更好理解。\n第一类错误和第二类错误不能同时变小 当样本容量固定时，不可能同时减少犯两类错误的概率，这是一对不可调和的矛盾。 但是当样本容量足够大时，犯这两类错误的概率通常都会变小。这是显然的，显然测的次数越多，对分布就越肯定。参书例 8.3.4.\n检验的真实水平 $\\alpha$ # 为什么 $\\alpha$ 很小？ 以投硬币为例。要想拒绝硬币正反概率相同的原假设，当我投出的硬币都是正面时，拒绝原假设的概率不应该很大吗？\n这种困惑在于混淆了事前设定的错误风险 ($\\alpha$) 和事后根据证据做出的决策（拒绝概率）。显著性水平 $\\alpha$ 是我们在开始投掷硬币之前就设定的一个风险上限，它的含义并不是我们最终拒绝它的概率，而是：如果硬币真的是公平的 ($H_0$ 成立)，我们错误地判断它不公平的概率最大是多少？\n而在原假设成立的情况下发生的概率我们叫它 P 值 P-value，也就是左边算出来的概率。P-value 不能太小，太小了就反常，俗称太阳从西边出来，大史称“邪乎到家必有鬼”。以上例中的硬币为例，假设硬币公平，投出十次正面的概率 $\\text{P-value}=\\theta^{10}=0.0009765625$，此时再跟 $\\alpha$ 比较，远远小于 $\\alpha$，就可以把 $H_{0}$ 拒绝了。这个例子中，拒绝概率应该是 $P(reject \\ H_{0} | \\theta)=1-\\text{P-value}$。\n我们知道 $\\alpha$ 代表犯第一类错误的概率上限，那么 $\\alpha$ 越大，表示对第一类错误容忍度越高，犯拒真错误的概率就越大，检验就越“大胆”——更激进地否认原假设 $H_{0}$。\n举例，原假设：此人是良民，而上边给的命令是：“宁可错杀八千，也不放过一个！”亦即：“你尽可以放心大胆地去否定原假设！”在这个例子中 $\\alpha$ 就相当大了。我们也称这个检定的真实水平或水平为 $\\alpha$。\n功效函数的上界限被称为真实水平（$size \\ \\alpha \\ test$）或水平（$level \\ \\alpha \\ test$）。似乎不太重要，省略不写了。\n接下来的重中之重应该在于 一致最大功效检验 UMP。感觉考试一定会狠狠考这部分，所以单独拿出来了。\n","date":"9 November 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C/%E5%81%87%E8%AE%BE%E6%A3%80%E9%AA%8C%E7%9A%84%E8%AF%84%E4%BB%B7/","section":"Posts","summary":"","title":"假设检验的评价","type":"posts"},{"content":"轨迹规划 (Trajectory Plan) | 知乎\n轨迹规划 # 轨迹规划的种类 # Joint Space 下的轨迹规划 # 定义末端执行器坐标系 ${T}$ 相对于世界坐标系 Global ${G}$ 的 initial, via, \u0026amp; final points, ${}^G T_i$ $i=1$ initial $i=2 \\sim N-1$ via points $i=N+1$ final 将 ${}^G T_i$ 以 $6$ 个参数方式（包含 3 个移动自由度和 3 个转动自由度）来表达 $$ ^G X_T = \\begin{bmatrix} ^G P_{T\\; org} \\\\ ROT({}^G \\hat{K}_T, \\theta) \\end{bmatrix} $$ Explaination 位置分量（3 个参数）： $^G P_{T; org}$ - $^G P_{T; org}$：这是从基坐标系 ${G}$ 的原点指向末端执行器坐标系 ${T}$ 原点的位置向量 (Position Vector)。 - 它通常是一个 $3 \\times 1$ 的向量，代表末端执行器在 ${G}$ 坐标系中的 $(x, y, z)$ 坐标。 姿态分量（3 个参数）： $ROT({}^G \\hat{K}_T, \\theta)$ - $ROT(\\dots)$：表示旋转 (Rotation) 或方向 (Orientation)。 - ${}^G \\hat{K}_T$ 和 $\\theta$：这表示使用轴 - 角 (Axis-Angle) 的方式来描述末端执行器相对于基坐标系 ${G}$ 的方向。 ${}^G \\hat{K}_T$ 是旋转的单位轴向量，在 ${G}$ 中表示。由于 $\\hat{K}_T$ 是单位向量（长度为 1），它只需要 2 个独立参数来定义方向。比如 $XY$ 平面的 45 度方向 $$ \u003e \\hat{K}_T = \\begin{bmatrix} \\frac{\\sqrt{2}}{2} \\\\ \\frac{\\sqrt{2}}{2} \\\\ 0 \\end{bmatrix} \u003e $$ $\\theta$ 是绕该轴旋转的角度。 将轴 - 角参数组合起来，可以用 3 个独立参数来表示一个三维旋转（例如，通过欧拉角 RPY 或轴 - 角向量 $\\theta\\hat{K}_T$ 的三个分量）。 对所有手臂末端点状态规划 smooth trajectories（其实就是插值） 将规划好手臂末端点状态的轨迹点经过 I.K.转换为关节 joint 状态：$^G X_T \\to \\Theta_t$ 检查 joint 状态在 Joint-space 下轨迹的可行性 Cartesian-space 笛卡尔空间 # 确定轨迹的起点 (Initial Point) - 途径点 (Via Point) - 终点 (Finial Point) 设计一条曲线将 Cartesian-space 所有点都平滑的连接起来。 使用 IK 计算出这条曲线在 Joint-space 的曲线。 检查 Joint-space 的曲线是否平滑。 对比 Cartesian \u0026amp; Joint space 的区别显而易见：进行规划的主体不同。Cartesian space 中直接对末端执行器进行数学规划，Joint space 则需要先把末端执行器的 space IK 成为 Joint space，再进行数学规划。\n轨迹规划算法 # 三次/五次多项式样条插值法 # 分 Cubic Polynomials Spline Interpolation 三次多项式方法和 Quintic Polynomials Spline Interpolation 五次样条插值法。这俩核心思想是一样的。\n在每一段轨迹 $P_{i} \\to P_{i+1}$ 上，用一个三次多项式来描述位置和时间的关系：\n$$ \\theta(t)=a_{0}+a_{1}t+a_{2}t^{2}+a_{3}t^{3}, t \\in [t_{i},t_{i+1}] $$ 为什么是三次多项式？ 因为我们在一段轨迹中，通常希望同时控制\n初始位置 $\\theta(t_{i})$ 终点位置 $\\theta(t_{i+1})$ 初始速度 $\\dot{\\theta}(t_i)$ 终点速度 $\\dot{\\theta}(t_{i+1})$ 三次函数正好有四个未知数，对应了上面能列出来的四个方程： $$ \u003e \\begin{cases} \u003e \\theta(t_i) = a_0 + a_1 t_i + a_2 t_i^2 + a_3 t_i^3 \\\\ \u003e \\dot{\\theta}(t_i) = a_1 + 2a_2 t_i + 3a_3 t_i^2 \\\\ \u003e \\theta(t_{i+1}) = a_0 + a_1 t_{i+1} + a_2 t_{i+1}^2 + a_3 t_{i+1}^3 \\\\ \u003e \\dot{\\theta}(t_{i+1}) = a_1 + 2a_2 t_{i+1} + 3a_3 t_{i+1}^2 \u003e \\end{cases} \\tag{1} \u003e $$ 如果再加上加速度连续性获得的两个方程，就可以是五次多项式方法。 $(1)$ 式是核心。为了满足每一段的轨迹相交且光滑，所以对任意两个相邻的多项式曲线而言，上一段的终点和下一段的起点是重合的，还需要满足此点处两条曲线的一次微分和二次微分相等。\n多段轨迹的连续性要求 # 对于一段由 $N$ 个路点 $P_0, P_1, \\dots, P_N$ 组成的轨迹，我们需要使用 $N$ 个三次多项式 $\\theta_i(t)$ 来连接相邻的路点 $P_i \\to P_{i+1}$。\n为了确保整个轨迹 $\\theta(t)$ 运动平稳，我们需要在**路点（连接点）**处满足一定的连续性条件。\n1. 位置连续性 (C0) # 在每一个路点 $P_i$ 处，前一段轨迹的终点位置必须等于后一段轨迹的起点位置。这是最基本的几何连续性。\n$$ \\theta_{i-1}(t_i) = \\theta_i(t_i) = P_i $$ 2. 速度连续性 (C1) # 速度的连续性是三次多项式方法最核心的要求，它确保了机械臂在经过路点时不会突然变速。\n$$ \\dot{\\theta}_{i-1}(t_i) = \\dot{\\theta}_i(t_i) $$ 3. 加速度连续性 (C2) # 更高阶的连续性要求是：\n$$ \\ddot{\\theta}_{i-1}(t_i) = \\ddot{\\theta}_i(t_i) $$然而，对于标准的三次多项式方法，我们通常只满足 C1 连续性（即速度连续），而无法保证 C2 连续性（即加速度连续）。C2 连续性是五次多项式方法。\n三次多项式的局限性 每一段三次多项式 $\\theta_i(t)$ 只有 4 个系数 ($a_0$ 到 $a_3$)，因此在一段轨迹中只能满足 4 个边界条件：\n$\\theta_i(t_i)$ 和 $\\dot{\\theta}_i(t_i)$\n$\\theta_i(t_{i+1})$ 和 $\\dot{\\theta}i(t{i+1})$\n即使在连接点 $t_i$ 处，我们强制要求：\n$\\dot{\\theta}_{i-1}(t_i) = \\dot{\\theta}_i(t_i)$（速度连续）\n加速度 $\\ddot{\\theta}(t)$ 在连接点是无法保证连续的。 加速度 $\\ddot{\\theta}(t)$ 是关于时间 $t$ 的线性函数，它的值由多项式系数决定，且通常会在路点处产生跳变。\n$$ \u003e \\ddot{\\theta}_i(t) = 2a_{2,i} + 6a_{3,i}t \u003e $$这意味着在整个轨迹的连接点处，机械臂会经历冲击 (Jerk)，需要更高级的五次多项式或样条曲线等方法来解决。\n速度规划：开放/封闭轨迹 # 开放式轨迹 (Open Trajectory) # 对于一条从起点 $P_0$ 到终点 $P_N$ 的开放式轨迹，我们需要确定 $N$ 个轨迹段的 $4N$ 个系数。我们有 $4N$ 个边界条件：\n起点/终点条件： $P_0$ 的 $\\theta(t_0), \\dot{\\theta}(t_0)$ 和 $P_N$ 的 $\\theta(t_N), \\dot{\\theta}(t_N)$（共 4 个已知条件）。 中间路点条件：对于 $N-1$ 个中间路点 $P_1, \\dots, P_{N-1}$，每个路点需要满足位置连续 ($\\theta_{i-1}(t_i) = \\theta_i(t_i)$) 和速度连续 ($\\dot{\\theta}_{i-1}(t_i) = \\dot{\\theta}_i(t_i)$)。（共 $2(N-1)$ 个约束）。 总边界条件数： $4 + 2(N-1) = 2N + 2$。\n缺失的条件： $4N - (2N+2) = 2N - 2$ 个自由度。\n如何补足自由度？ 我们需要为 $N-1$ 个中间路点指定速度 $\\dot{\\theta}(t_i)$。通常有以下方法：\n全部指定为零： 机械臂在每个路点处停止，路径清晰，但效率低（适用于“通过路点”的任务）。\n内插速度： 使用某种平滑的内插方法（例如，通过相邻路点和时间计算出近似的连续速度，如三次样条中的速度计算）来确定中间速度。\n封闭式轨迹 (Closed Trajectory) # 如果轨迹是首尾相接的 ($P_N = P_0$)，则还需要满足首尾相接点的连续性：\n$$ \\theta_{N-1}(t_N) = \\theta_0(t_0) $$$$ \\dot{\\theta}_{N-1}(t_N) = \\dot{\\theta}_0(t_0) $$这增加了额外的约束，常用于循环作业或周期性运动的规划。\nCode # Robotics Toolbox for Python (RTB) 可以用来求解。一般工业上都用五次多项式。\npip install roboticstoolbox-python numpy matplotlib import numpy as np import roboticstoolbox as rtb import matplotlib.pyplot as plt # --- 1. 定义轨迹参数 --- # 机械臂的自由度 (DOF) DOF = 6 # 起始关节角度 (q0, 位置 P0) [rad] # 假设机械臂从零位开始 q0 = np.zeros(DOF) # 终止关节角度 (qf, 位置 Pf) [rad] # 假设关节 1, 2, 3 移动到特定角度 qf = np.array([np.pi/4, np.pi/6, -np.pi/8, 0, 0, 0]) # 轨迹持续时间 (秒) T_total = 4.0 # 轨迹点数量 (用于绘图和控制的采样点) N = 101 # 生成时间向量 t = np.linspace(0, T_total, N) # --- 2. 使用 jtraj() 生成轨迹 --- # rtb.jtraj() 默认使用五次多项式 (quintic polynomial) # 默认的边界条件是： # 初始速度 qd0 = 0, 初始加速度 qdd0 = 0 # 终点速度 qdf = 0, 终点加速度 qddf = 0 # 这确保了轨迹是 C2 连续的。 # 注意: q0 和 qf 必须是 NumPy 数组或列表 traj = rtb.jtraj(q0, qf, t) # --- 3. 提取轨迹数据 --- q_traj = traj.q # 关节位置矩阵 (N x DOF) qd_traj = traj.qd # 关节速度矩阵 (N x DOF) qdd_traj = traj.qdd # 关节加速度矩阵 (N x DOF) # 打印检查 print(f\u0026#34;总轨迹点数量: {q_traj.shape[0]}\u0026#34;) print(f\u0026#34;起始位置 (q0): {q_traj[0, :3].round(4)}\u0026#34;) print(f\u0026#34;终点位置 (qf): {q_traj[-1, :3].round(4)}\u0026#34;) print(f\u0026#34;终点速度 (qd_f): {qd_traj[-1, :3].round(4)}\u0026#34;) print(f\u0026#34;终点加速度 (qdd_f): {qdd_traj[-1, :3].round(4)}\u0026#34;) # 终点速度和加速度都应接近于0 # --- 4. 轨迹可视化 (以第一个关节为例) --- joint_index = 0 # 查看第一个关节 (q1) 的运动 plt.figure(figsize=(12, 9)) # 1. 位置 plt.subplot(3, 1, 1) plt.plot(t, q_traj[:, joint_index]) plt.title(f\u0026#39;Joint {joint_index+1} Trajectory - Position $\\\\theta(t)$\u0026#39;) plt.ylabel(\u0026#39;Position (rad)\u0026#39;) plt.grid(True) # 2. 速度 plt.subplot(3, 1, 2) plt.plot(t, qd_traj[:, joint_index], color=\u0026#39;orange\u0026#39;) plt.title(f\u0026#39;Joint {joint_index+1} Trajectory - Velocity $\\\\dot{\\\\theta}(t)$\u0026#39;) plt.ylabel(\u0026#39;Velocity (rad/s)\u0026#39;) plt.grid(True) # 检查边界速度是否为零 plt.scatter([t[0], t[-1]], [qd_traj[0, joint_index], qd_traj[-1, joint_index]], color=\u0026#39;black\u0026#39;) # 3. 加速度 plt.subplot(3, 1, 3) plt.plot(t, qdd_traj[:, joint_index], color=\u0026#39;red\u0026#39;) plt.title(f\u0026#39;Joint {joint_index+1} Trajectory - Acceleration $\\\\ddot{\\\\theta}(t)$\u0026#39;) plt.xlabel(\u0026#39;Time (s)\u0026#39;) plt.ylabel(\u0026#39;Acceleration (rad/s²)\u0026#39;) plt.grid(True) # 检查边界加速度是否为零 plt.scatter([t[0], t[-1]], [qdd_traj[0, joint_index], qdd_traj[-1, joint_index]], color=\u0026#39;black\u0026#39;) plt.tight_layout() plt.show() ","date":"21 October 2025","externalUrl":null,"permalink":"/posts/ai/eai/robotics/%E8%BD%A8%E8%BF%B9%E8%A7%84%E5%88%92/","section":"Posts","summary":"","title":"轨迹规划","type":"posts"},{"content":" 机械臂正运动学 (Forward Kinematics, FK) # MDH (Modified Denavit-Hartenberg) 参数 # 通常把地面 ground 作为 i=0 的杆（link）。坐标系有可能不在实物上，你不能把实物当成抽象。\n元素 符号 描述 连杆长度 $a_{i-1}$ 沿 $X_{i-1}$ 轴测量，从 $Z_{i-1}$ 到 $Z_i$ 的距离。 连杆扭角 $\\alpha_{i-1}$ 绕 $X_{i-1}$ 轴测量，从 $Z_{i-1}$ 到 $Z_i$ 的角度。 关节距离 $d_{i}$ 沿 $Z_i$ 轴测量，从 $X_{i-1}$ 到 $X_i$ 的距离。 关节角 $\\theta_{i}$ 绕 $Z_i$ 轴测量，从 $X_{i-1}$ 到 $X_i$ 的角度。 MDH 坐标系建立规则。按 $Z-X-Y$ 的顺序去定：\n坐标系 $i$ 固连在连杆 $i$ 上。通常取地面作为 i=0 的杆。 $Z_i$ 轴沿关节 $i$ 的轴线方向。 $X_i$ 轴沿 $Z_i$ 和 $Z_{i+1}$ 的公垂线方向，或在公垂线为 0 时根据规则选择。 $Y_{i}$ 根据 $X_{i}$ 和 $Z_{i}$ 由右手定则确定。 坐标系 ${i}$ 建立在连杆 $i$ 的末端。 变换矩阵 # 从 $i-1 \\to i$ 的步骤：\n先对齐 $Z_{i-1} \\to Z_{i}$ 轴。绕 $X_{i-1}$ 轴转过两个转轴之间的差角 $\\alpha_{i-1}$（这一步旋转，两杆已经平行了）。 做平移，沿 $X_{i-1}$ 杆平移 $a_{i-1}$。此时两个坐标系 $Z$ 轴重合。 对齐 $X_{i-1} \\to X_{i}$ 轴，转过 $\\theta_{i}$。这不是为了对齐 $Z$ 轴，而是为了对齐公共法线 $X$ 轴。 沿 $Z_{i}$ 轴平移 $d_{i}$，对齐两个坐标系的原点。 Difference between Standard D-H and Modified D-H 特性 标准 D-H (SDH) 改进型 D-H (MDH) 坐标系 ${i}$ 固连位置 固连在连杆 $i$ 的输入端（即关节 $i$ 处）。 固连在连杆 $i$ 的输出端（即关节 $i+1$ 处）。 变换顺序 绕 $X_{i-1}$ 旋转 $\\alpha_{i-1}$ $\\to$ 沿 $X_{i-1}$ 平移 $a_{i-1}$ $\\to$ 绕 $Z_i$ 旋转 $\\theta_i$ $\\to$ 沿 $Z_i$ 平移 $d_i$ 绕 $Z_{i-1}$ 旋转 $\\theta_i$ $\\to$ 沿 $Z_{i-1}$ 平移 $d_i$ $\\to$ 绕 $X_i$ 旋转 $\\alpha_i$ $\\to$ 沿 $X_i$ 平移 $a_i$ 通过 MDH 参数，可以定义从连杆坐标系 ${i}$ 到 ${i-1}$ 的齐次变换矩阵 ${}{i}^{i-1}\\mathbf{T}$。即我们知道了右边，如何推到左边。下面这个式子右乘上 $P{i}$ 就能推导到左边 $P_{i-1}$ 了。\n$$ \\begin{align} {}{i}^{i-1}\\mathbf{T} \u0026amp;= \\text{Rot}(x, \\alpha{i-1}) \\cdot \\text{Trans}(x, a_{i-1}) \\cdot \\text{Rot}(z, \\theta_i) \\cdot \\text{Trans}(z, d_i) \\\n\u0026amp;=\\begin{pmatrix} \\cos\\theta_i \u0026amp; -\\sin\\theta_i \u0026amp; 0 \u0026amp; a_{i-1} \\ \\sin\\theta_i \\cos\\alpha_{i-1} \u0026amp; \\cos\\theta_i \\cos\\alpha_{i-1} \u0026amp; -\\sin\\alpha_{i-1} \u0026amp; -d_i \\sin\\alpha_{i-1} \\ \\sin\\theta_i \\sin\\alpha_{i-1} \u0026amp; \\cos\\theta_i \\sin\\alpha_{i-1} \u0026amp; \\cos\\alpha_{i-1} \u0026amp; d_i \\cos\\alpha_{i-1} \\ 0 \u0026amp; 0 \u0026amp; 0 \u0026amp; 1 \\end{pmatrix} \\end{align} $$\n最终的末端执行器坐标系 ${N}$ 相对于基坐标系 ${0}$ 的总变换矩阵 $\\mathbf{T}_N^0$ 是所有连杆变换矩阵的连乘：\n$$ {}_N^0\\mathbf{T} = {}_1^0\\mathbf{T} {}_2^1\\mathbf{T} \\cdots {}_N^{N-1}\\mathbf{T} = \\begin{pmatrix} \\mathbf{R} \u0026 \\mathbf{P} \\\\ \\mathbf{0}^T \u0026 1 \\end{pmatrix} $$其中 $\\mathbf{R}$ 是 $3 \\times 3$ 的旋转矩阵（表示姿态），$\\mathbf{P}$ 是 $3 \\times 1$ 的位置向量。\n机械臂逆运动学 (Inverse Kinematics, IK) # 为了实现对机器人的任务规划和控制（“我要到那里，关节应该怎么动？”），逆运动学输入末端执行器的位姿矩阵 $\\mathbf{T}$，输出所有关节变量 $\\theta_i$ 或 $d_i$。\n这个问题的解非唯一确定。如图，我们已知了 $(x,y)$，若要求出两个关节的参数，那么会有至少两组解，即图中的实线和虚线。通常需要根据实际约束（如关节限制、避障、最快/最节能等）来选择最优解。\n求解问题：\nReachable workspace: 可达空间 Dexterous workspace: 手臂可以以任意姿态到达的空间 求解方法 # IK 求解主要分为两类：\n解析法（Analytic Solutions） # 适用于具有特定几何特征（如球形手腕）的机器人，能够得到精确的闭式解 (Closed-form solution)。能由闭式解的话求解速度很快，因此目前大多机械手臂都设计成具有解析解。\n解耦： 通过将机器人分解为手臂（位置）和手腕（姿态）两部分来简化问题。 手臂位置：通常利用几何法或代数法求解前三个关节角。 手腕姿态：对于具有球形手腕（三个关节轴线交于一点）的机器人，可以通过逆变换或欧拉角分解独立求解后三个关节角。 几何法：直接利用几何关系（如余弦定理）求解角度。 代数法：通过将 $\\mathbf{T}_N^0$ 矩阵的元素与 FK 连乘展开后的三角函数表达式进行匹配和求解。 代数法主要通过左乘连杆变换矩阵的逆，逐步分离关节变量：\n$$ {}_1^0\\mathbf{T}^{-1} \\cdot {}_N^0\\mathbf{T} = {}_2^1\\mathbf{T} \\cdots {}_N^{N-1}\\mathbf{T} $$几何法通过余弦定理求解关节角。感觉是个纯平面几何的问题，就不多说了。\n$$ \\cos\\theta_2 = \\frac{x^2 + y^2 - l_1^2 - l_2^2}{2 l_1 l_2} \\quad \\implies \\theta_2 = \\pm \\text{atan2}\\left(\\sqrt{1 - \\cos^2\\theta_2}, \\cos\\theta_2\\right) $$ 数值法（Numerical Solutions） # Note 感觉这一块儿理论和数学的内容很多。实际上要掌握调库应该就可以\n适用于几何结构复杂、无法得到解析解的机器人，通过迭代逼近来寻找近似解。\n基础：基于迭代优化，通常需要机器人雅可比矩阵 $\\mathbf{J}$。 过程：通过计算末端位姿误差 $\\Delta \\mathbf{X}$，并利用 $\\Delta \\mathbf{X} = \\mathbf{J} \\Delta \\mathbf{\\Theta}$ 来迭代更新关节角 $\\mathbf{\\Theta}$，直到误差足够小。 雅可比矩阵 $\\mathbf{J}$：描述关节速度与末端执行器线速度和角速度之间的关系，是 IK 数值解法的核心。 缺点：初始猜测值敏感、收敛速度慢、可能陷入局部最优解、计算量大。 微分运动学关系：末端执行器的广义速度 $\\dot{\\mathbf{X}}$ 与关节速度 $\\dot{\\mathbf{\\Theta}}$ 的关系：\n$$ \\dot{\\mathbf{X}} = \\mathbf{J}(\\mathbf{\\Theta}) \\dot{\\mathbf{\\Theta}} $$IK 数值迭代，利用雅可比矩阵的伪逆 $\\mathbf{J}^{+}$ 来求解关节修正量 $\\Delta\\mathbf{\\Theta}_k$\n$$ \\mathbf{\\Theta}_{k+1} = \\mathbf{\\Theta}_k + \\Delta\\mathbf{\\Theta}_k \\quad \\text{其中} \\quad \\Delta\\mathbf{\\Theta}_k = \\mathbf{J}(\\mathbf{\\Theta}_k)^{+} \\Delta\\mathbf{X}_k $$雅可比伪逆 (Moore-Penrose Pseudoinverse)。当 $\\mathbf{J}$ 是 $m \\times n$ 矩阵时：\n$$ \\mathbf{J}^{+} = \\mathbf{J}^T (\\mathbf{J} \\mathbf{J}^T)^{-1} \\quad (\\text{当 } n \u003c m \\text{ 时，左伪逆}) \\mathbf{J}^{+} = (\\mathbf{J}^T \\mathbf{J})^{-1} \\mathbf{J}^T \\quad (\\text{当 } n \u003e m \\text{ 时，右伪逆}) $$误差由相对变换矩阵 $\\mathbf{T}_{\\text{error}}$ 提取（包含位置误差 $\\Delta\\mathbf{p}$ 和姿态误差 $\\Delta\\boldsymbol{\\phi}$）\n$$ \\mathbf{T}_{\\text{error}} = \\mathbf{T}_{\\text{current}}^{-1} \\mathbf{T}_{\\text{target}} = \\begin{pmatrix} \\mathbf{R}_e \u0026 \\Delta\\mathbf{p} \\\\ \\mathbf{0}^T \u0026 1 \\end{pmatrix} \\quad \\implies \\Delta\\mathbf{X}_k = \\begin{pmatrix} \\Delta\\mathbf{p} \\\\ \\Delta\\boldsymbol{\\phi} \\end{pmatrix} $$ Code # 实际的 KDL、Track-IK 或 IKFast 库通常需要复杂的机器人描述文件 URDF 文件。实际机械臂的 D-H/MDH 参数多达 $4N$ 个（$N$ 是关节数）\n使用 pykdl-all 可以构造一个简单的 KDL 运动链。\nimport PyKDL as kdl import numpy as np # --- 1. Define the Robot Kinematic Chain --- # Assuming a simple 3R arm (three Revolute joints) # Joint axes are all rotating around Z-axis # kdl.Joint() constructor argument: type (RotZ) chain = kdl.Chain() # Link 1: Joint rotates around Z, Link length 1.0 (along X) chain.addSegment(kdl.Segment(kdl.Joint(kdl.Joint.RotZ), kdl.Frame.DH(1.0, 0.0, 0.0, 0.0))) # kdl.Frame.DH(a, alpha, d, theta) - corresponds to D-H parameters # Link 2: Joint rotates around Z, Link length 1.0 (along X) chain.addSegment(kdl.Segment(kdl.Joint(kdl.Joint.RotZ), kdl.Frame.DH(1.0, 0.0, 0.0, 0.0))) # Link 3: Joint rotates around Z, Link length 0.5 (as end effector) chain.addSegment(kdl.Segment(kdl.Joint(kdl.Joint.RotZ), kdl.Frame.DH(0.5, 0.0, 0.0, 0.0))) # --- 2. Initialize Solvers --- # Define number of joints (N=3) num_joints = chain.getNrOfJoints() # Joint arrays (kdl.JntArray is KDL\u0026#39;s vector type) q_init = kdl.JntArray(num_joints) q_out = kdl.JntArray(num_joints) # Initial Joint Guess q_init[0], q_init[1], q_init[2] = 0.1, 0.1, 0.1 # Forward Kinematics Solver (required) fk_solver = kdl.ChainFkSolverPos_recursive(chain) # Inverse Kinematics Velocity Solver (required for numerical IK) ik_v_solver = kdl.ChainIkSolverVel_pinv(chain) # Inverse Kinematics Position Solver (Numerical Iterative Solver: Newton-Raphson) # Max Iterations = 100, Epsilon = 1e-6 (Convergence precision) ik_p_solver = kdl.ChainIkSolverPos_NR(chain, fk_solver, ik_v_solver, 100, 1e-6) # --- 3. Define Target Frame --- # Target Position P(x, y, z) = (1.5, 0.5, 0.0) P_target = kdl.Vector(1.5, 0.5, 0.0) # Target Orientation R (No rotation / Identity) R_target = kdl.Rotation.RPY(0.0, 0.0, 0.0) # Target Homogeneous Transformation Matrix T_target T_target = kdl.Frame(R_target, P_target) # --- 4. Execute IK Solution --- # Call IK solver: (initial angles, target pose, output angles) status = ik_p_solver.CartToJnt(q_init, T_target, q_out) # --- 5. Output Results --- print(\u0026#34;--- PyKDL (Numerical IK) Demonstration ---\u0026#34;) print(f\u0026#34;Target Position: ({P_target[0]:f}, {P_target[1]:f}, {P_target[2]:f})\u0026#34;) if status \u0026gt;= 0: print(\u0026#34;Solution SUCCESSFUL!\u0026#34;) thetas = [q_out[i] for i in range(num_joints)] print(f\u0026#34;Solved Joint Angles (rad): {np.round(thetas, 4)}\u0026#34;) # Verification (FK) T_check = kdl.Frame() fk_solver.JntToCart(q_out, T_check) print(f\u0026#34;Verification Position (FK): ({T_check.p[0]:f}, {T_check.p[1]:f}, {T_check.p[2]:f})\u0026#34;) else: print(\u0026#34;Solution FAILED! Try changing the initial guess or target pose.\u0026#34;) ","date":"16 October 2025","externalUrl":null,"permalink":"/posts/ai/eai/robotics/%E6%9C%BA%E6%A2%B0%E8%87%82%E8%BF%90%E5%8A%A8%E5%AD%A6/","section":"Posts","summary":"","title":"机械臂运动学","type":"posts"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/robotics/","section":"Tags","summary":"","title":"Robotics","type":"tags"},{"content":"","date":"11 October 2025","externalUrl":null,"permalink":"/tags/","section":"Tags","summary":"","title":"Tags","type":"tags"},{"content":" 欧拉角的万向锁现象 # 看了很多篇博客，很多都举了转手机的例子，但是本人天生愚笨，一点也没看懂。今天细细研究才发现原来漏了关键的一点啊，而很多博客竟都对此讳莫如深。\n转手机实验 用自己的手机做一个试验，你把手机屏幕朝上，手机的长边为 Z 轴，短边为 Y 轴，X 轴垂直屏幕向下，那先绕 X 轴（垂直屏幕）旋转一下手机，假设旋转 30 度，然后再把手机绕 Y 轴（短边）旋转 90 度，也就是把手机短边接触桌面竖立起来，这时候你再绕 Z 轴（长边）以任意角度旋转，你会发现手机的 Y 轴（短边）一直定在桌面上不可能脱离桌面，这就是万向锁现象。\n很蒙对不对！说实话我也没搞懂，但是网上的资料都是这么写的。😭不怪你，是它不够严谨，后面我会解释的。\n分析一下这个过程：\n你先绕 X 轴旋转 30∘（这个角度不重要）。 关键是绕 Y 轴旋转 90∘，这使得原来的 Z 轴（垂直屏幕向下）现在和原来的 Z 轴（长边）对齐了，并且它们都与桌面平行。 现在的结果： 当你再尝试绕 Z 轴（长边）以任意角度旋转时，你发现手机的 Y 轴（短边）始终贴在桌面上。这表明绕 Z 轴的旋转本质上与绕 X 轴的旋转是同一个动作，只是方向相反或相同。那你要问了：第三点里怎么能是一个动作呢？现在绕 X 轴（也就是垂直屏幕的方向）旋转明明可以把手机的短边抬离桌面啊！ 诶！这就是核心点了。欧拉角这个逆天的设定有最重要的一条，而这一条全网大多数人没说，只有下面的这个视频说了：前面（或者说外部轴）的转动，会带着后面（内部轴）一起转，而内部轴不能带动外部轴转动！比如在 ZYX 欧拉角中，我们转 $x$ 轴，那么 $y$、$z$ 轴要跟着转；而转 $y$ 轴只有 $z$ 轴跟着转，转 $z$ 轴谁都不跟着转。\n为什么要这样逆天的设定呢？这是人为设定的吗？还真不是。我们说欧拉角变换是一个变换“过程”，变换都是相对于初始状态，变换的顺序很重要——比如我们规定先 Z 再 Y 后 X 旋转，那么 $(30,90,0)$ 这个变换和 $(1,30,90)$ 这个变换，都得先对 $z$ 轴旋转，再对 $y$、$x$ 旋转，不能说第一个变换看见 $z$ 轴没转或转的少，那就直接跳过它先转 $y$、$x$ 二轴。\n这就解释清楚了为什么外部轴带动内部轴转动。要是还不清楚，看下面的视频吧。\n我们再用数学解释一下。这个数学也许跟网上的数学不太一样，如果想看旋转 90 度角是怎么影响万向锁转向的，请任搜一篇博客。我们讲的东西在《机器人学导论（原书第三版）》的 P43，参照本节开头的例子，使用 Z-Y-X 欧拉角，即规定了绕轴的顺序。\n我们很容易知道欧拉角的变换就相当于是左乘一个旋转矩阵，那么整个旋转过程就相当于：\n$$ {}^A_{B}R={}^A_{B'}R \\ {}^{B'}_{B''}R \\ {}_{B}^{B''}R $$其中 $B\u0026rsquo;\u0026rsquo;$ 和 $B\u0026rsquo;$ 都是转过对应轴的中间过程。\n本文里不妨直接写作 ${}^A_{B}R = R_{x}(\\phi) R_{y}(\\theta) R_{z}(\\psi)$ 吧，参考开头的飞机图。注意，旋转变换是不断左乘一个矩阵，所以先进行的变换靠右，而后进行的变换乘在左边。\n🤓👆写到这里你应该悟了吧！Z-Y-X 欧拉角中，我们对 $z$ 轴旋转完成，然后对 $y$ 轴旋转的时候，由于矩阵乘法 $R_{y}(\\theta) R_{z}(\\psi)$，势必会同时影响到 $z$ 轴，让它跟着一起转，而并不会影响到后转的 $x$ 轴（此时 $R_{x}(\\phi)$ 还没有乘进来）。\n重新回顾一下转手机的过程：Z-Y-X 欧拉角，先绕 x 轴旋转 30 度导致 y 轴 z 轴都跟着转（注意此时 x 轴垂直桌面），再绕 y 轴旋转 90 度，此时 z 轴会跟着旋转到垂直桌面，而 x 轴没变，依然垂直桌面！最后我们转 x 轴和 z 轴得到的结果就是一样的了。🙋看到了吗！我们丢失了一个自由度！！这就是我们朝思暮想的万向锁啊！！\n万向死锁的表现是：丢失了一个轴 (或叫丢失了一个自由度)；是欧拉角表达不唯一的重要体现形式之一。\n本文采用 CC BY 4.0 国际许可协议 进行许可。转载请注明原文作者、出处及本文链接。\n","date":"11 October 2025","externalUrl":null,"permalink":"/posts/ai/eai/robotics/%E6%AC%A7%E6%8B%89%E8%A7%92%E7%9A%84%E4%B8%87%E5%90%91%E9%94%81%E7%8E%B0%E8%B1%A1/","section":"Posts","summary":"","title":"欧拉角的万向锁现象","type":"posts"},{"content":" 如何嵌入 B 站视频 # 本来不必写这篇博客的，因为网上有很多方法。直到 2025 年 10 月 10 日，我发现 b 站删除了网页端的分享按钮！那么网上的很多方法都失效了，我之前看过的、教人如何在 obsidian 插入 b 站视频的博客也随之删除了。\n那我只有自己写一下了，以免 b 站以后删除更多 API。\n参考：\nBilibili 弹幕文件的解析 关于博客园内嵌入bilibili视频 - 王陸 - 博客园 这是官方准备的嵌入代码，目前看来还没封，可以直接拿来用：\n\u0026lt;iframe src=\u0026#34;https://player.bilibili.com/player.html?isOutside=true\u0026amp;bvid=BV1Nr4y1j7kn\u0026amp;p=1\u0026amp;autoplay=false\u0026#34; scrolling=\u0026#34;no\u0026#34; border=\u0026#34;0\u0026#34; frameborder=\u0026#34;no\u0026#34; framespacing=\u0026#34;0\u0026#34; allowfullscreen=\u0026#34;true\u0026#34; width=\u0026#34;60%\u0026#34; height=300\u0026gt;\u0026lt;/iframe\u0026gt; 使用方法：把上面的链接中，aid、cid 或者 bvid 替换成你视频的对应项，三选一即可。其中 bvid 可以通过页面 url 直接拿到（那个大小写数字混合的就是 bvid，如 BV1Wv3xeNEds）。\n显然写 bvid 是最方便的。其余的拿不到，但为了防止 b 站更改 api，本博客也记一下其他的可以通过以下这个链接查到：\nhttps://api.bilibili.com/x/web-interface/view?bvid= 常用的参数（加在 src 里面，如上面例子的 autoplay=false）\nkey 说明 page 第几个视频，起始下标为 1 （默认值也是为 1)）就是 B 站视频，选集里的，第几个视频 as_wide 是否宽屏。1： 宽屏，0:：小屏 high_quality 是否高清。1：高清，0：最低视频质量 (默认) 如视频有 360p 720p 1080p 三种，默认或者 high_quality=0 是最低 360p high_quality=1 是最高 1080p danmaku 是否开启弹幕。1：开启 (默认)，0：关闭 autoplay 是否自动播放 ","date":"10 October 2025","externalUrl":null,"permalink":"/posts/dev/%E5%A6%82%E4%BD%95%E5%B5%8C%E5%85%A5b%E7%AB%99%E8%A7%86%E9%A2%91/","section":"Posts","summary":"","title":"如何嵌入b站视频","type":"posts"},{"content":" 旋转矩阵、欧拉角、四元数 # 哎！感慨一下当时学图形学和 Unity 的时候就要会这些概念，可惜当时没好好学。现在老大徒伤悲了。\n旋转矩阵 # 坐标系与位姿变换 里说过这一节了。本质上就是 ${}_{B}^AR$，表示从 $B$ 坐标系到 $A$ 坐标系的旋转变换。\n一个矩阵 R 是旋转矩阵，当且仅当它满足以下两个条件：\n正交矩阵（Orthogonal Matrix）： 它的逆矩阵等于它的转置矩阵，即 $R^{-1}=R^T$。 这保证了旋转是等距变换（保持向量长度不变， $∥Rv∥=∥v∥$）。 行列式为 1： $det(R)=1$。 这保证了旋转是真正的旋转，而不是旋转加反射（如果行列式为 -1，则包含了一个反射）。 在二维平面上，将一个向量 $v=(x,y)$ 逆时针旋转 $θ$ 角，旋转后的新向量 $v\u0026rsquo;=Rv$。对应的旋转矩阵 $R$ 为： $$ \\mathbf{R}(\\theta) = \\begin{pmatrix} \\cos\\theta \u0026 -\\sin\\theta \\\\ \\sin\\theta \u0026 \\cos\\theta \\end{pmatrix} $$ 绕 X 轴旋转 (Roll)\n$$ \\mathbf{R}_x(\\theta) = \\begin{pmatrix} 1 \u0026 0 \u0026 0 \\\\ 0 \u0026 \\cos\\theta \u0026 -\\sin\\theta \\\\ 0 \u0026 \\sin\\theta \u0026 \\cos\\theta \\end{pmatrix} $$绕 Y 轴旋转 (Pitch)\n$$ \\mathbf{R}_y(\\theta) = \\begin{pmatrix} \\cos\\theta \u0026 0 \u0026 \\sin\\theta \\\\ 0 \u0026 1 \u0026 0 \\\\ -\\sin\\theta \u0026 0 \u0026 \\cos\\theta \\end{pmatrix} $$绕 Z 轴旋转 (Yaw)\n$$ \\mathbf{R}_z(\\theta) = \\begin{pmatrix} \\cos\\theta \u0026 -\\sin\\theta \u0026 0 \\\\ \\sin\\theta \u0026 \\cos\\theta \u0026 0 \\\\ 0 \u0026 0 \u0026 1 \\end{pmatrix} $$$v$ 先绕 $X$ 再绕 $Y$：$v\u0026rsquo;=\\mathbb{R}{x}R{y}v$\n旋转矩阵缺点比较多：\n不直观 矩阵占据了更多的内存 由于浮点精度的限制，大量的矩阵乘法最终可能导致病态矩阵，这种现象称作“矩阵蠕变”，矩阵正交化能解决矩阵蠕变的问题，因为乘起来都是 0 了。 欧拉角 # 欧拉角是带有顺序的三元组。欧拉角的定义很不同，有静态和动态定义。动态定义指的是绕物体本地的坐标轴进行旋转（如动图 2）。航空领域通常采用的旋转方式是 ZYX 顺序（称作 Tait-Bryan angles），下图是一架飞机按照 ZYX 组合进行旋转产生欧拉角的过程，其中，ψ为偏航角（yaw），θ为俯仰角（pitch），φ为滚转角（roll）。\n欧拉角的优势是直观，要显示和键盘输入方位时，欧拉角是唯一的选择，但劣势是：\n给定方位的表达方式不唯一（欧拉角的万向锁现象） 角度之间求插值非常困难 四元数 Quaternions # Understanding Quaternions | 3D Game Engine Programming\n二维平面上的旋转：复数 # 复数基础与二维空间旋转 - 何雨龙 - 博客园\n四元数的思想来源于复数。高中学过，二维平面上的点 $(a,b)$ 可以用复数表示为 $z = a + bi$，而写成极坐标就很容易看出和旋转的关系：\n$$ z = a+bi = r\\cos \\theta + ir \\sin \\theta = r(\\cos \\theta+i\\sin\\theta) $$由欧拉公式\n$$ e^{i\\theta}=\\cos \\theta + i \\sin \\theta $$上式可写作\n$$ z = re^{i\\theta} $$$r$ 指的是向量的模长，$\\theta$ 是幅角，即与 $x$ 轴之间的夹角。\n两个复数相乘表示旋转。\n$$ z_{1}z_{2}=r_{1}r_{2}e^{i({\\theta_{1}+\\theta_{2})}} $$即相乘之后模长变为原模长的乘积，幅角变为原幅角之和。\n那么表示纯旋转的旋转角显然是模长为 1 只有纯角度的单位复数。被称为旋转子（Rotator）：\n$$ R_{\\theta}=\\cos \\theta + i \\sin \\theta = e^{i\\theta} $$如点 $(1,3)$ 进行 $\\frac{\\pi}{4}$ 的旋转：$(1+3i) * e^{i \\frac{\\pi}{4}}=(1+3i)*\\left( \\frac{\\sqrt{ 2 }}{2}+i \\frac{\\sqrt{ 2 }}{2} \\right)$\n三维空间旋转：四元数 # 运算基础 # 四元数形式：\n$$ \\begin{align} q \u0026= s + x i + y j + z k \\\\ q \u0026= [s, \\mathbf{v}], s \\in R, v \\in R^3 \\end{align} $$类似地，\n$$ \\begin{align} i^{2}=j^{2}=k^{2}=ijk=-1 \\ ij=k,ji=-k \\ jk=i,kj=-i \\ ki=j,ik=-j \\\n\\end{align} $$\n这种关系很像是三维坐标系下，三个单位向量叉乘的关系：$\\mathbf{x} \\times \\mathbf{y}=\\mathbf{z}, \\ \\mathbf{y} \\times \\mathbf{x} = \\mathbf{-z}$ 这种，两两叉乘为剩余的正交向量。\n四则运算遵循复数的法则，在这里说一下乘法。稍加推导可得：\n$$ [s_{a},\\mathbf{a}][s_{b}, \\mathbf{b}] = [s_{a}s_{b} - \\mathbf{a}\\mathbf{b}, s_{a}\\mathbf{b}+s_{b}\\mathbf{a}+a \\times b] $$用 $q^*$ 表示共轭四元数：\n$$ \\begin{align} q\u0026=[s,\\mathbf{v}] \\\\ q^*\u0026=[s,\\mathbf{-v}] \\\\ qq^*\u0026=[s^{2}+v^{2},\\mathbf{0}]=|q|^{2} \\end{align} $$四元数的逆\n$$ \\begin{align} q^{-1}\u0026=\\frac{q^*}{|q|^{2}} \\\\ qq^{-1}\u0026=\\frac{qq^*}{|q|^{2}}=1 \\end{align} $$ 旋转 # 空间中，三维向量表示为纯四元数，即实部为 0 的四元数：\n$$ \\mathbf{v}_{q}=[0, \\mathbf{v}] $$一个表示旋转的单位四元数 $\\mathbf{q}$ 可以写成：\n$$ \\mathbf{q} = \\cos\\left(\\frac{\\theta}{2}\\right) + \\mathbf{u} \\sin\\left(\\frac{\\theta}{2}\\right) $$在进行旋转操作时，就是将这个实部为零的四元数 $\\mathbf{p}_q$ 夹在旋转四元数 $\\mathbf{q}$ 及其逆（或共轭，因为旋转四元数为单位四元数，所以 $|q|=1$） $\\mathbf{q}^{-1}$ 之间进行计算：\n$$ \\mathbf{v}'_q = \\mathbf{q} \\mathbf{v}_q \\mathbf{q}^{-1} $$得到的 $\\mathbf{v}\u0026rsquo;_q$ 依然为纯四元数，其中虚部就是旋转之后向量的坐标。实部为 1 的四元数表示 0 度旋转。\n相互转换 # 知乎-鸡哥-三维旋转：欧拉角、四元数、旋转矩阵、轴角之间的转换\n","date":"10 October 2025","externalUrl":null,"permalink":"/posts/ai/eai/robotics/%E5%A7%BF%E6%80%81%E6%8F%8F%E8%BF%B0%E6%97%8B%E8%BD%AC%E7%9F%A9%E9%98%B5%E6%AC%A7%E6%8B%89%E8%A7%92%E4%B8%8E%E4%B8%87%E5%90%91%E9%94%81%E5%9B%9B%E5%85%83%E6%95%B0/","section":"Posts","summary":"","title":"姿态描述：旋转矩阵、欧拉角与万向锁、四元数","type":"posts"},{"content":" 坐标系与位姿变换 # 这一章相关内容在《机器人学导论（原书第三版）》2.2 节。\nPreliminary Notations # $^{A}P$ ，$P$ 表示 Position，一个位置坐标。左上角的符号表示在 $A$ 坐标系下。 ${}_{B}^AR$，$R$ 表示 Rotation，旋转，和平移一起统称叫变换（后面有个字母 $T$ 就涵盖了这两个过程）。左下角和左上角的坐标，表示 $B$ 坐标系相对于 $A$ 坐标系的变换。变换显然是个动词，所以肯定得有相对的概念。 总之，这一张明白什么是坐标系 Frame，什么是位置 Position，什么是变换 Transform 就行。 位置\u0026amp;姿态：描述机器人状态的基石 # 我们把机械臂想象成人体的大臂 + 小臂 + 手，那么很容易观察到这么一个现象：大臂绕躯干运动，小臂绕大臂运动，手绕小臂运动。一个机械臂就是这么组成的。我们如果简化一下，假想人的小臂大臂都为刚体（高中物理竞赛学的概念，如果不那么好想那就想象一条钢管），手和小臂是一个整体（统称为手臂），灵活地绕着肘关节活动，那么便抽象出了机器人学里位置与姿态的概念。\n位置就是大臂之于躯干的位置，如果我们把躯干叫做世界 s 坐标系 World Frame的话，就很容易知道位置可以用一个空间中的三维向量 $P=\\begin{bmatrix}P_{x} \\ P_{y} \\ P_{z}\\end{bmatrix}$ 来表示。这一块儿太简单了，就像我们很容易知道肘关节在躯干的哪里一样。我们把世界坐标系用 $A=\\begin{bmatrix}\\hat{X_{A}} \\ \\hat{Y_{A}} \\ \\hat{Z_{A}}\\end{bmatrix}$ 来表示。\n怎么说呢…我觉得完全可以把 $A$ 当作世界坐标系，但是书上似乎不是这么写的，他追求了更普遍的表示——用 $U$（Universe） 表示世界坐标系。后面注意一下就行。\n而姿态，就是小臂相对于肘关节的位置。很容易想到手（机械臂末端）在小臂的作用下可以平移，在小臂和手腕的共同作用下可以旋转，很灵巧。相对于机械臂末端执行器（也就是肘关节）来说，我们可以给末端（手）建立一个局部坐标系 Body Frame，来描述它的姿态——是如何相对于末端执行器进行各种妖娆的平移和旋转的。把局部坐标系用 ${}^AB=\\begin{bmatrix}{}^A\\hat{X_{B}} \\ {}^A\\hat{Y_{B}} \\ {}^A\\hat{Z_{B}}\\end{bmatrix}$ 表示。\n这里有几点。第一，我自认为局部坐标系没有讲清楚，那么请把大拇指、食指和中指三个指头充分张开，就像判定磁感线方向那样。这就是一个局部坐标系 B，接下来感受一下它是如何相对于你身体的世界坐标 t 系运动的；第二，局部坐标系的左上标 ${}^AB$，表示B 相对于 A。\n坐标变换的一般式 # 旋转变换是左乘一个旋转矩阵。左上角的 $A$ 表示在 $A$ 坐标系中，那 ${}^A \\mathbf{\\hat{X}}_B$ 就指的是在 $A$ 坐标系中表示 $B$ 坐标系单位矢量的坐标。\n$$ {}^A_{B} \\mathbf{R} = \\begin{bmatrix} \\vert \u0026 \\vert \u0026 \\vert \\\\ {}^A \\mathbf{\\hat{X}}_B \u0026 {}^A \\mathbf{\\hat{Y}}_B \u0026 {}^A \\mathbf{\\hat{Z}}_B \\\\ \\vert \u0026 \\vert \u0026 \\vert \\end{bmatrix} $$ 旋转变换 矢量 $P$ 从 $B$ 坐标系表示旋转变换到 $A$ 坐标系表示。下面的 $R$ 指的是 Rotate。 $$ \u003e {}^A P = {}_{B}^{A}R {}^{B}P \\tag{1} \u003e $$ 正交矩阵的逆等于转置 所以 ${}^A_{B}R={}{A}^BR^{-1}={}{A}^BR^{T}$。也就是说坐标系 $B$ 相对于坐标系 $A$ 的变换矩阵，等于 $A$ 坐标系相对于 $B$ 坐标系的变换矩阵的逆。\n平移变换过于简单，直接加一个平移矢量就行。\n综合变换（位姿变换） 矢量 $P$ 从 $B$ 坐标系表示综合平移和旋转变换到 $A$ 坐标系表示。 $$ \u003e {}^A P = {}^A_{B} R {}^B P + {}^A P_{B\\mathbf{ORG}} \\tag{2} \u003e $$ 这个 ORG 的意思是 origin，原点，表示 A 坐标系表示下 B 的原点的坐标。\n旋转控制姿态，平移控制位置。\n坐标变换齐次式 # 这块在相机的内外参，以及机器学习里都有这样的技巧，那就是我们上节的非齐次式不好看，那就扩张一个常数维度，变成齐次的：\n$$ {}^A P = {}_{B}^{A} T \\ \\mathbf{}{}^BP $$这个 $T$ 是 4*4 的矩阵，称为齐次变换矩阵。上式亦即：\n$$ \\begin{bmatrix} {}^A \\mathbf{P} \\ 1 \\end{bmatrix} # \\begin{bmatrix} \\begin{array}{c|c} {}^A_B \\mathbf{R} \u0026amp; {}^A \\mathbf{P}_{B\\mathbf{ORG}} \\ \\hline 0\\ 0\\ 0 \u0026amp; 1 \\end{array} \\end{bmatrix} \\begin{bmatrix} {}^B \\mathbf{P} \\ 1 \\end{bmatrix} \\tag{3} $$\n这种方法让计算机忙于冗余的 01 乘法，不如 (2) 快，所以仅用作简化理论推导。\n","date":"9 October 2025","externalUrl":null,"permalink":"/posts/ai/eai/robotics/%E5%9D%90%E6%A0%87%E7%B3%BB%E4%B8%8E%E4%BD%8D%E5%A7%BF%E5%8F%98%E6%8D%A2/","section":"Posts","summary":"","title":"坐标系与位姿变换","type":"posts"},{"content":" 参数估计的基本方法：频率替换估计、矩估计、极大似然估计 # 参数估计在机器学习中运用非常多（详见 PRML，我记得里面有很大的篇幅去讲如何估计高斯分布）。那么参数估计是解决一个什么样的问题呢？假设我们有一个高斯分布 $N(\\mu, \\sigma^{2})$，我们并不知道它的 $\\mu, \\theta$，但是有很多采样得到的数据点 $x_{1},x_{2},\\dots ,x_{n}$，便可以利用这些数据去估计分布的参数 $\\mu, \\theta$。此之谓参数估计。\n传统的估计方法：频率替换估计（Frequency Substitution Estimate）、矩估计（Moments Estimate） # 频率替换估计十分简单，只需用抽样所得的频率 $\\frac{m}{n}$（m 是样本的个数，n 是总体）去替换模型中的概率 $p$ 即可。上面的例子，$\\mu=\\frac{1}{n}\\sum x_{i}$，$\\sigma=\\frac{1}{n}\\sum(x_{i}-\\bar{x})^{2}$，这就完成了对参数的估计。\n其实上面的例子已经有点超出频率替换估计的范畴了——说“频率”，为什么要用到 $\\sigma$ 呢？诶！还真是，但只用频率去替换 $\\mu$ 只能够列出一个方程，显然不够解具有两个参数的方程嘛！所以上面的例子确实超纲了，但是稍微往前走一点，我们就走到了矩估计的范畴。\n矩的概念：\n原点矩（Moments about the Origin）：$\\mu_{k}=E[X^{k}]$，一阶原点距 $E[X]$，二阶原点矩 $E[X^{2}]$，…，k 阶原点矩 $E[X^{k}]$ 中心矩（Central Moments）：$μ_{k}​=E[(X−μ)^k]$，同样也有一阶、二阶、k 阶云云。 好吧。其实我们没必要去记也没必要去刻意用什么矩去估计，只需要手边已知了什么矩，去找对应的量列方程就行。就像例子里，均值和方差比较好求，那我们就用均值和方差。\n最重要的估计方法：极大似然估计（Maximum Likelihood Estimation） # 我实在是不想写极大似然估计了！这一块儿很重要，但是网上的博客太多了，各个写得都比我好。我只想解释最重要的一点：似然的含义是衡量一件事情有多可能（likelihood），比如在一个学校里，男生穿裙子这件事情的似然（likelihood）就很低。而极大似然函数 $L$ 就是干这个事情的。我们假设参数 $\\theta$，便可以写出关于 $\\theta$ 的函数 $L(\\theta)$，然后去根据样本 $X=x_{1},x_{2},\\dots,x_{n}$，去令 $L(\\theta | X)$（时常会加 $\\ln$ 变成对数似然函数 $\\ln \\ L(\\theta|X)$） 尽可能大，也就是让样本出现尽可能合理，这就是极大似然估计的思想。\n估计的连续映射性质 # 设 $g(x)$ 是连续函数，已知对参数 $X$ 的估计是 $\\hat{\\theta}$，则对于参数 $g(X)$ 的估计就是 $g(\\hat{\\theta})$。比如我们已知了参数 $p$ 的估计是 $\\hat{p}$，那么参数 $\\frac{1}{p}$ 的估计就是 $\\frac{1}{\\hat{p}}$。\n","date":"30 September 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E7%82%B9%E4%BC%B0%E8%AE%A1/%E5%9F%BA%E6%9C%AC%E5%8F%82%E6%95%B0%E4%BC%B0%E8%AE%A1%E6%B3%95/","section":"Posts","summary":"","title":"基本参数估计法","type":"posts"},{"content":" 充分统计量 # 充分统计量 | 知乎\n什么是充分统计量 # 统计量：$(X_{1},X_{2},\\dots,X_{n})$ 是样本，如果如果由此样本构造一个函数 $T(X_{1},X_{2},\\dots,X_{n})$ 中不含任何未知数，那么它就是样本的统计量。常见的统计量如样本的方差、均值等。\n充分统计量指能浓缩样本信息的量。这是什么意思呢？比如你是一个检察官，你有一箱罪证。你不是把这一箱罪证都报告给上级，而是写成一个凝练的报告包含了罪证的全部信息，如“犯罪人员的平均身高”、“案发地点的平均光照强度”等等。这些量就是“充分统计量”。\n数学上来讲，如果我们已知充分统计量的情况下，样本分布便不含参数，那就叫做浓缩了样本信息。比如我们考虑 $X_{1},X_{2},\\dots,X_{n}\\sim B(1，p)$，如果我们已知了样本之和 $T = \\sum_{i=1}^n{X_{i}} = t$，那么联合分布列：\n$$ P(X_{1},X_{2},\\dots,X_{n}|T=t)= \\frac{P\\left( X_{1}=x_{1},X_{2}=x_{2},\\dots,X_{n}=t-\\sum_{i=1}^{n-1}x_{i} \\right)}{P(T=t)}=\\frac{p^t(1-p)^{n-t}}{C_{n}^{t}p^t(1-p)^{n-t}}=\\frac{1}{C_{n}^t} $$ 为什么是这个式子 分母很简单，知道总共有 t 个 1（二项分布之和为 t），那么有 $C_{n}^t$ 种选法，乘上后面的因子；分子固定了 $x_{1},x_{2},\\dots,x_{n}$，最后一个变量 $X_{n}$ 只能等于 $t-\\sum_{i=1}^{n-1}x_{i}$。注意没有排列组合因子，因为是固定的。\n还是很懵，对吧？举个例子，$n=5$ 的情况下，如果已知五个样本的和为 3，那么 $X_{1},X_{2},\\dots,X_{n}$ 的联合分布将不再是一个函数，而是一个定值——$\\frac{1}{C_{5}^3}=\\frac{1}{10}$。呃，这个值似乎挺好理解，因为知道总共有 5 个数，从中取 3 个为 1 就行，那么它的联合分布就只有 $C_{5}^3$ 种可能性，概率也就是 $\\frac{1}{C_{5}^3}$ 了。至于“联合分布为常数”，意思是：在满足条件（即 $T=t$）的那些样本向量之间，概率是均匀分布的。\n一般来说，样本的均值 $\\bar{X}$、方差这种量都是充分统计量，而 $X_{1}+X_{2}$ 这种就不是，因为它“不能表征样本的全貌”。换句话说即使我们知道了 $X_{1}+X_{2}=t$，那剩下的数字也得依靠参数 $p$ 来求。\n需要知道的是，充分统计量一一变换之后得到的统计量，也是充分统计量。\nQuote 若 $T(x)$ 是充分统计量，$g(t)$ 是一一对应的实函数（可以是向量函数），则 $g(T(x))$ 也是充分统计量。\nExample 例如，如果 $T(x)=\\sum x_{i}^2$ 是充分统计量，那么 $T\u0026rsquo;(x)=\\sum(x_{i}-\\bar{x})^2$ 也是充分统计量。\n求或者判定充分统计量：因式分解定理（Fisher-Neyman 准则） # 若联合分布函数 $p(x;\\theta)$，其中 $\\theta$ 为未知参数。则 $T(x)$ 为充分统计量当且仅当存在：\n$$ p(x;\\theta)=g(T(x),\\theta)h(x) $$简单来讲，我们只要写出联合分布函数 $p(x;\\theta)$，看能不能够分解成两个因式，其中一个因式 $h(x)$ 只与样本 $x$ 有关（这个 $h(x)$ 可以恒为常数，比如 $h(x)\\equiv 1$），另一个 $g(T(x),\\theta)$ 与样本 $x$ 和参数 $\\theta$ 都有关。\n以上的定理简化了不少内容，不过大致理解足够了。这个分解告诉我们：\n左边：似然函数 $L(θ;x)$（总信息） 这是我们从样本中提取的关于 $θ$ 的所有信息。 右边第一项：$g(T(x);θ)$（充分信息） 这是带有参数 $θ$ 的部分。它必须只通过统计量 $T(X)$ 来影响似然函数的值。这意味着所有与 $θ$ 有关的样本信息都已经被 $T(X)$ 打包进去了。 右边第二项：$h(x)$（无关信息） 。由于它不含 $θ$，所以对我们推断 $θ$ 没有任何帮助。这部分信息是样本数据中固有的，但与我们想估计的参数是无关的。 极小充分统计量 # 【极小充分统计量】如果一个充分统计量 $T^{\\star}(X)$ 有：对任意充分统计量，都能存在映射 $\\phi$ 使得 $T^{\\star }(X)=\\phi(T(X))$，那么称 $T^{\\star}(X)$ 为极小充分统计量。\n这句话的逻辑在于，这个统计量可以通过任何充分统计量精简得到。\n完备统计量 # 【完备分布族（complete family of distributions）】设 ${P_\\theta:\\theta\\in\\Theta}$ 是一个分布族。若对任意可测函数 $g(X)$，只要\n$$ E_\\theta[g(X)]=0 \\quad \\text{对所有 } \\theta\\in\\Theta $$就必然推出\n$$ P_\\theta(g(X)=0)=1 \\quad \\text{对所有 } \\theta\\in\\Theta, $$则称该分布族是完备的。\n【完备统计量（complete statistic）】设 $T=T(X)$ 是样本的一个统计量。如果在分布族 ${P_\\theta}$ 下，对任意函数 $h(T)$，只要\n$$ E_\\theta[h(T)]=0 \\quad \\text{对所有 } \\theta $$就推出\n$$ P_\\theta(h(T)=0)=1 \\quad \\text{对所有 } \\theta, $$则称 $T$ 是关于该分布族的完备统计量。\n完备充分统计量的求解——吃灰挖土法 # 那么对于完备充分统计量的求解，就要涉及指数族分布（或称指数型分布族）了。因为其要找出四个函数 $c(\\theta)$、$h(x_1, \\dots, x_n)$、$w(\\theta)$、$T(x_1, \\dots, x_n)$，而 $chwT$ 的首字母对应着很应双十一景的“吃灰挖土”，便以此进行记忆。\n具体地，在我们求解完概率密度函数 $p(x_1, \\dots, x_n; \\theta)$ 后，如果我们能将其分解为：\n$$ p(x_1, \\dots, x_n; \\theta) = c(\\theta) h(x_1, \\dots, x_n) \\exp \\{w(\\theta) T(x_1, \\dots, x_n)\\} $$的话，并且 $w(\\theta)$ 的值域有内点，则此时的 $T(x_1, \\dots, x_n)$ 即为完备充分统计量。\n【例】比如我们现在求出联合密度函数为\n$$ p(x_1, \\dots, x_n; \\theta) = \\frac{1}{\\theta^n} \\exp \\{ -\\frac{1}{\\theta} \\sum_{i=1}^n x_i \\} I_{\\{x_{(1)}\u003e0\\}} (x_1, \\dots, x_n), \\quad \\theta \u003e 0 $$那么这时候对应的“吃灰挖土”即为：$c(\\theta) = \\frac{1}{\\theta^n}$, $h(x_1, \\dots, x_n) = I_{{x_{(1)}\u0026gt;0}} (x_1, \\dots, x_n)$, $w(\\theta) = -\\frac{1}{\\theta}$, $T(x_1, \\dots, x_n) = \\sum_{i=1}^n x_i$。\n然后我们看 $w(\\theta)$ 和内点的概念：所谓值域有内点，就是存在一个内点，其邻域包含在值域内。比如 $(0, 10)$ 这个值域有内点，但 $0$ 和 $10$ 显然不是内点。显然内点这东西很难没有，大家做题的时候默认值域总是有内点就行了。比如这里我们就应该说 $w(\\theta) = -\\frac{1}{\\theta}$ 的值域是 $(-\\infty, 0) \\ (\\theta \u0026gt; 0)$，有内点（无脑写有就行了）。\n","date":"28 September 2025","externalUrl":null,"permalink":"/posts/ai/statics/%E7%82%B9%E4%BC%B0%E8%AE%A1/%E5%85%85%E5%88%86%E7%BB%9F%E8%AE%A1%E9%87%8F/","section":"Posts","summary":"","title":"充分统计量","type":"posts"},{"content":"","date":"26 September 2025","externalUrl":null,"permalink":"/tags/rl/","section":"Tags","summary":"","title":"RL","type":"tags"},{"content":" 霍夫丁不等式 (Hoeffding\u0026rsquo;s inequality)，与多臂赌博机 (MAB) 中的上置信界 (UCB) 算法 # 多臂老虎机\n霍夫丁不等式 (Hoeffding\u0026rsquo;s inequality) # 设有两两独立的随机变量 $X_1, \\dots, X_n !$，那么它们的经验期望值（含义见后）：\n$$ \\overline{X} = \\frac{X_1 + \\cdots + X_n}{n} $$满足：\n$$ \\mathbb{P}(\\overline{X} - \\mathbb{E}[\\overline{X}] \\geq t) \\leq \\exp \\left( - \\frac{2t^2n^2}{\\sum_{i=1}^n (b_i - a_i)^2} \\right),\\! $$令 $\\bar{X}=-\\bar{X}$：\n$$ \\mathbb{P}(\\mathbb{E}[\\overline{X}]-\\overline{X} \\geq t) \\leq \\exp \\left( - \\frac{2t^2n^2}{\\sum_{i=1}^n (b_i - a_i)^2} \\right),\\! $$进而可得（注意有个绝对值）：\n$$ \\mathbb{P}(|\\overline{X} - \\mathbb{E}[\\overline{X}]| \\geq t) \\leq 2\\exp \\left( - \\frac{2t^2n^2}{\\sum_{i=1}^n (b_i - a_i)^2} \\right),\\! $$其中 $\\mathbb{P}(X_i \\in [a_i, b_i]) \\approx 1 !$，即变量 $X_i$ 几乎必然满足 $a_i\\leqslant X_i \\leqslant b_i ,$\n经验期望 (Empirical Expectation) # 经验期望是根据有限的观测数据来估计总体期望。假设我们有一组数据 $x_1,x_2,…,x_n$，这些数据是来自一个随机变量 $X$ 的独立同分布 (i.i.d.) 样本。那么，经验期望（或者说样本均值）的定义为：\n$$ \\mathbb{\\hat{E}}[X]=\\frac{1}{n}\\sum_{i=1}^{n}x_i $$这个公式表示将所有样本值加起来后除以样本个数，得到的结果就是经验期望，它是对总体期望 $\\mathbb{E}(X)$ 的一个估计。﻿\n多臂赌博机中的上置信界 # 这是在读 《动手学深度学习》 的上置信界算法（upper confidence bound，UCB）时产生的思考。UCB 是怎么取的呢？假设当某一个臂被摇了 n 次（在动作 Action $a$）之后，产生的累计效益 $\\hat{Q}(a)$ 依然很低时，我们值不值得再去摇它呢？\n霍夫丁不等式可以说明这个问题。经验期望是在有限次观察下，该臂所产生的效益 $\\hat{Q}(a)$。注意，我们的 $\\hat{Q}(a) =\\frac{1}{n}\\sum_{i=1}^{n}r_i$，其中 r 指 reward。在观察次数足够多（long term）的时候，$\\hat{Q}(a)$ 应该会趋近于其期望 $\\mathbb{E}[Q(a)]$。注意，经验期望是不稳定，不一定可信的，而期望指长期观察结果，是赌博机的固有属性，稳定又可信。\n那么，$\\hat{Q}(a)$ 与其期望的“偏差”就是上文霍夫丁不等式中的 $t$。“偏差”越大，就越“值得”探索。这个“偏差”就是不确定性度量 uncertainty $U(a)$。\n进而，如果我们令不等式右边 exp 那一坨为概率 $p$，可以得知 （以下简称某一臂摇动获得的效益 $\\hat{Q}(a)$ 为“经验效益”，效益的期望为“真实期望”，不确定性度量 uncertainty 为 $u$）：\n真实期望比经验效益还多 $u$，这件事的概率至多为 $p$； 真实期望不超过我们观测到的经验效益 +$u$，这件事的概率至少为 $1-p$； 随着次数 $n$ 越来越多，$p$ 也在越来越小，所以（2）变得越来越可信，即：真实期望有一个上限值，这个上限值就是我们观测到的经验效益 + 不确定性度量 $u$。 上置信界算法便选取期望奖励上界最大的动作。注意这个“期望奖励上界”肯定指真实期望，我们毕竟是要估算赌博机的固有属性，长期期望的。 我们每次选择的是，期望奖励上界最大的摇臂。 接下来就是不太明白为什么 UCB 算法比 $\\epsilon$-gready 算法的累计懊悔还多了。\n","date":"26 September 2025","externalUrl":null,"permalink":"/posts/ai/rl/%E9%9C%8D%E5%A4%AB%E4%B8%81%E4%B8%8D%E7%AD%89%E5%BC%8F%E5%92%8C%E4%B8%8A%E7%95%8C%E7%BD%AE%E4%BF%A1%E7%AE%97%E6%B3%95/","section":"Posts","summary":"","title":"霍夫丁不等式和上界置信算法","type":"posts"},{"content":" 容器操作 # STL 常用容器操作对照表 # 容器 初始化方法 增 (Insert) 删 (Erase) 查 (Find / Access) 改 (Update) 备注 / 底层实现 vector vector\u0026lt;T\u0026gt; v;, vector\u0026lt;T\u0026gt; v(n, val); push_back / insert / emplace pop_back / erase / clear 随机访问 [] / at [] / at 直接修改 动态数组，连续内存，支持随机访问 deque deque\u0026lt;T\u0026gt; d;, deque\u0026lt;T\u0026gt; d(n, val); push_back / push_front / insert / emplace pop_back / pop_front / erase / clear 随机访问 [] / at [] / at 直接修改 分段连续内存，支持两端高效操作 list list\u0026lt;T\u0026gt; l;, list\u0026lt;T\u0026gt; l(n, val); push_back / push_front / insert / emplace pop_back / pop_front / erase / clear 迭代器遍历查找 迭代器指向元素可修改 双向链表，节点分散存储 map map\u0026lt;K,V\u0026gt; m;, map\u0026lt;K,V\u0026gt; m{{k1,v1},{k2,v2}}; insert / emplace / operator[] erase / clear find / count / lower_bound / upper_bound operator[] 修改 value 红黑树，有序唯一键值对 multimap multimap\u0026lt;K,V\u0026gt; m; insert / emplace erase / clear find / count / lower_bound / upper_bound / equal_range ❌ key 不可改，value 可改 红黑树，有序，允许重复 key unordered_map unordered_map\u0026lt;K,V\u0026gt; m; insert / emplace / operator[] erase / clear find / count operator[] 修改 value 哈希表，无序唯一键值对 set set\u0026lt;T\u0026gt; s;, set\u0026lt;T\u0026gt; s{val1, val2}; insert / emplace erase / clear find / count / lower_bound / upper_bound ❌ 不可直接修改元素 红黑树，有序唯一集合 multiset multiset\u0026lt;T\u0026gt; s; insert / emplace erase / clear find / count / lower_bound / upper_bound / equal_range ❌ 不可直接修改元素 红黑树，有序，允许重复元素 unordered_set unordered_set\u0026lt;T\u0026gt; s; insert / emplace erase / clear find / count ❌ 不可直接修改元素 哈希表，无序唯一集合 stack stack\u0026lt;T\u0026gt; s;, stack\u0026lt;T, deque\u0026lt;T\u0026gt;\u0026gt; s; push / emplace pop top top() 修改 适配器，默认基于 deque 实现 queue queue\u0026lt;T\u0026gt; q;, queue\u0026lt;T, deque\u0026lt;T\u0026gt;\u0026gt; q; push / emplace pop front / back front() / back() 修改 适配器，默认基于 deque 实现 priority_queue priority_queue\u0026lt;T\u0026gt; pq;, priority_queue\u0026lt;T, vector\u0026lt;T\u0026gt;, less\u0026lt;T\u0026gt;\u0026gt; pq; push / emplace pop top ❌ 不能直接修改元素 适配器，默认基于 vector + 堆 (heap) 实现 Python 常用数据结构操作对照表 # 容器 初始化方法 增 (Insert) 删 (Erase) 查 (Find / Access) 改 (Update) 备注 / 底层实现 list lst = [], lst = [val1, val2] append / insert / extend pop / remove / clear 下标 [] / index / 遍历 [] 直接修改 动态数组（类似 C++ vector），支持随机访问 deque (collections.deque) from collections import deque; d = deque() append / appendleft / extend / extendleft pop / popleft / remove / clear 下标 []（部分实现支持 O(1)）/ 遍历 [] 修改元素 双端队列，基于双向链表/块状数组，适合两端操作 set s = set(), s = {val1, val2} add / update remove / discard / pop / clear in 成员检测 ❌ 不可直接修改元素 哈希表实现，无序唯一集合 frozenset fs = frozenset([val1, val2]) ❌ 不可添加 ❌ 不可删除 in 成员检测 ❌ 不可修改 不可变集合，哈希表实现 dict d = {}, d = {k1:v1, k2:v2} dict[key] = value / update / setdefault pop(key) / popitem / clear / del dict[key] / get / in dict[key] = new_value 哈希表实现，无序（Python 3.7+ 保持插入顺序） defaultdict (collections) from collections import defaultdict; d = defaultdict(type) defaultdict[type] 自动插入 同 dict 同 dict 同 dict dict 的子类，缺省值自动生成 OrderedDict (collections) from collections import OrderedDict; od = OrderedDict() update / move_to_end pop / popitem / clear 同 dict 同 dict dict 的子类，记录插入顺序（Python 3.7+ 已默认） Counter (collections) from collections import Counter; c = Counter() update subtract / clear counter[key] / elements / most_common counter[key] = new_val 计数器，本质是 dict 的子类 heapq (最小堆) import heapq; h = [] heappush heappop / heapreplace / heappushpop 最小值 heap[0] ❌ 不可直接修改元素（需 pop+push） 基于最小堆，默认最小值优先 queue.Queue from queue import Queue; q = Queue() put get queue[0] (不推荐) / get_nowait ❌ 不能直接改 线程安全队列，基于锁实现 LifoQueue from queue import LifoQueue; q = LifoQueue() put get queue[-1] (不推荐) ❌ 栈结构，线程安全 PriorityQueue from queue import PriorityQueue; pq = PriorityQueue() put (存 (priority, item)) get 最小优先级元素 ❌ 基于 heapq 实现，线程安全 Go 常用数据结构操作对照表 # 容器 初始化方法 增 (Insert) 删 (Erase) 查 (Find / Access) 改 (Update) 备注 / 底层实现 slice s := []T{}, s := make([]T, len, cap) append / copy 手动截断（如 s = append(s[:i], s[i+1:]…)） 下标 s[i] s[i] = val 动态数组，底层基于数组 + 容量自动扩容（类似 C++ vector / Python list） array var a [n]T, a := [n]T{val1, val2} 固定长度，初始化时赋值 ❌ 长度固定不可删 下标 a[i] a[i] = val 固定长度数组，值类型 map m := map[K]V{}, m := make(map[K]V) m[key] = value delete(m, key) m[key] / value, ok := m[key] m[key] = newValue 哈希表实现，键唯一，无序（Go 1.12+ 随机迭代顺序） struct var s T, s := T{field1: val1} 直接定义字段赋值 ❌ 无直接删除（可设零值） s.field s.field = val 自定义复合数据类型，类似 C 结构体 list (container/list) import \u0026quot;container/list\u0026quot;; l := list.New() PushBack / PushFront / InsertAfter / InsertBefore Remove(element) 遍历迭代器 Front() / Back() / Next() element.Value = newVal 双向链表实现，元素非连续存储 heap (container/heap) import \u0026quot;container/heap\u0026quot;; h := \u0026amp;HeapType{} heap.Push heap.Pop h[0] 最小元素 ❌ 不可直接修改（需 Pop+Push） 基于最小堆，需要实现 heap.Interface ring (container/ring) import \u0026quot;container/ring\u0026quot;; r := ring.New(n) r.Link 连接环 r.Unlink(n) r.Value / r.Next() / r.Prev() r.Value = val 环形链表，适合循环队列 sync.Map import \u0026quot;sync\u0026quot;; var m sync.Map Store(key, val) Delete(key) Load(key) / LoadOrStore Store(key, newVal) 并发安全哈希表，适合多线程场景 chan (channel) ch := make(chan T), ch := make(chan T, cap) ch \u0026lt;val 发送 ❌ 无删除，需 close(ch) \u0026lt;-ch 接收 ❌ 不支持修改 CSP 并发模型，底层队列，线程安全 ","date":"20 August 2025","externalUrl":null,"permalink":"/posts/dev/%E6%95%B0%E6%8D%AE%E7%BB%93%E6%9E%84%E5%AE%B9%E5%99%A8%E6%93%8D%E4%BD%9C/","section":"Posts","summary":"","title":"数据结构容器操作","type":"posts"},{"content":"","date":"13 August 2025","externalUrl":null,"permalink":"/tags/flow/","section":"Tags","summary":"","title":"Flow","type":"tags"},{"content":" Flow Matching # 参考资料：\n知乎-深入解析Flow Matching技术 回忆的话看这个就够了 下面的视频推导得也很详细：\n这个 flow-matching 网上的讲解似乎不止一个版本，李宏毅老师讲了一个基于反函数的 flow-matching (OpenAI GLOW, 2018) 算法。本篇的内容相较于 GLOW 是比较新的，基于论文 [2210.02747] Flow Matching for Generative Modeling，这个算法也是 Stable Diffusion 3 的基础。\nFlow 的数学直觉 # Flow matching 的基本假设很符合直觉，建立关键概念的数学直觉，远比推导本身要更重要。\n在 flow matching 中，$x \\sim p_{t}(x)$ 是从分布 $p_{t}(x)$ 里采样得到的数据。我们假设有一个随时间 $t \\in [0,1]$ 变化的过程，可以一步一步地把一个混沌初开、一团噪声的初始分布 $p_{0}(x)$ 变化为我们想要的目标分布 $p_{1}(x)$。那么我们在初始分布时采样的数据就是 $x_{0} \\sim p_{0}(x)$，在目标分布采样的数据就是 $x_{1} \\sim p_{1}(x)$。\n$p_{0}(x)$ 不一定为高斯分布，$p_{1}(x)$ 也不一定训练数据的分布 注意这里我并没有把初始分布假设为高斯分布，原文也没有，因为它其实可以为很多种分布——只是推导到最后发现高斯分布是一种最好计算的情况。\n至于 $p_{1}(x)$，也并不一定是训练数据。原文和后文中训练数据的分布是 $q(x_{1})$，而我们的目的就是要让最后的分布 $p_{1}(x_{1})$ 尽可能逼近 $q(x_{1})$。\n所以我们的 $x_{t}$、$p_{t}(x)$ 都是会随着时间 $t$ 变化的，都是在朝着尽可能地从一个任意分布到目标分布的方向去变化。那么我们就可以定义 flow 和向量场 $v$ 的概念：\n$$ \\frac{d \\phi_{t}(x_{t})}{dt}=v_{\\theta}(x_{t},t) $$$x_{t}$ 就是粒子群，我们的 flow 就是 $\\phi_{t}$，是一个描述 $x_{t}$ 空间上变化的函数，初始的一群粒子 $x_{0}$ 在向量场 $v_{\\theta}$ 的推动下，自发朝着目标 $x_{1}$ 移动，这个过程仿佛是河流里的一堆水分子在重力势能的作用下往低处流一样。\n向量场 $v_{\\theta}$，是 flow 对时间 $t$ 的导函数，反映的是 flow 作用下的粒子群，在下一个时间里往哪里走。而应该注意到它带了 $\\theta$，就说明 $v_{\\theta}$ 其实是我们要拟合的一个目标。$u_{t}$ 是 GroundTruth，要用神经网络 $v_{\\theta }$ 拟合 $u_{t}$。\n再阐释一下概念 想象在 diffusion 的去噪过程中，要将一团噪声（$x_0$）平滑地变成一张清晰的图像（$x_1$）。\n我们在噪声和图像之间定义了一条路径（Path），记为 $x_t$。初始时采样 $x_{0}$，最终采样 $x_{1}$ $u_t$ 就是这条路径在 $t$ 时刻的 时间导数（Time Derivative），也就是 $\\frac{d}{dt}x_t$。它告诉模型：“在这个时间点，数据点应该往哪个方向移动、移动多快，才能最终变成目标图像。” $v_{\\theta,t}$ 是我们要去拟合 $u_{t}$ 的目标，由神经网络给出。 这么想清楚了的话，损失函数便呼之欲出：\n$$ \\mathcal{L}_{FM}=\\mathbb{E}_{t,p_{t}(x)}[||v_{\\theta,t}-u_{t}||^2_{2}] \\tag 1 $$仔细观察之，损失函数表示求一个 L2 损失，在什么范围内求呢？在所有时间尺度 $t \\in [0,1]$ 和所有概率路径 $p_{t}(x)$ 上！说实话，我们的粒子流 $x_{0}$ 运动的路径千千万，既可以走直线直接到 $x_{1}$（这里埋个伏笔），也可以歪七扭八地走到 $x_{1}$，甚至还有可能到不了 $x_{1}$，我怎么能够在所有概率路径上求积分呢？这就是论文要解决的问题。\nConditional Flow Matching # 按直觉来说，$p_{t}(x)$ 代表 $x_{0} \\to x_{1}$ 的概率路径千千万，但弱水三千，若是只取一瓢饮，不就很好嘛？\n那我们取最终能到达 $x_{1}$ 的那条。那你可能会说 $x_{0}$ 还能走不到 $x_{1}$？还真有可能，谁规定山顶流下的水流就一定能到达最终的目的地？\n数学表达式是这样的：\n$$ p_{1}(x)=\\int p_{1}(x|x_{1})q(x_{1})dx_{1} \\approx q(x) $$$p_{1}(x)$ 是 $t=1$ 时刻的分布，$q(x_{1})$ 是训练数据集在最后粒子群 $x_{1}$ 上的分布，我们想要 $p_{1}(x)$ 最终逼近 $q(x)$ 也就是训练数据集上的分布。\n论文花了很大篇幅证明，在 假设一个 condition（也就是用单一样本）：$x_{0}$ 能到达 $x_{1}$ 的概率路径上计算的损失函数 (2)，相比对所有概率路径（也就是对整个分布）求损失函数 (1)，算出的梯度是一样的。这个方法在论文中叫Conditional Flow Matching (CFM)\n$$ \\mathcal{L}_{cfm}=\\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}[||v_{\\theta,t}(x)-u_{t}(x)||_{2}^2] \\tag 2 $$ Optimal Transport Conditional VFs # 论文其实还证了很多东西，如果要完整理解的话可以看开头提到的视频。我觉得推了这么多结果用的最多的其实是最简单的一种情况，所以没必要事无巨细地去理解。\n这个最简单的情况就是 Optimal Transport，它是说粒子群从 $x_{0} \\to x_{1}$，最优路径肯定是直线过去，即：\n$$ x_{t}​=(1−t)x_{0}+tx_{1}​ $$也就是 $x_{t}$ 是 $x_{0}$ 与 $x_{1}$ 之间的线性差值。它的速度场和 $x_{t}$ 无关：\n$$ u_{t}=\\frac{dx_{t}}{dt}=x_{1}-x_{0} $$损失函数：\n$$ \\mathcal{L}_{cfm}=\\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}[||v_{\\theta,t}(x)-u_{t}(x)||_{2}^2]=\\mathbb{E}_{t,q(x_{1}),p_{t}(x|x_{1})}[||v_{\\theta}(x,t)+x_{0}-x_{1}||_{2}^2] $$完事儿之后就可以训练了！\n训推过程 # Training # 训练过程：\nfor all $x_{1}$ in training dataset: $t \\sim \\text{Uniform}(0,1)$ 采样得到得到一个时间步 $t$ $x_{0} \\sim N(0,1)$ 采样得到高斯噪声作为起始粒子群 $x_{0}$ $x_{t}=(1-t)x_{0}+tx_{1}$ 计算出 $t$ 时刻的粒子群 $x_{t}$ $u_{t}=x_{1}-x_{0}$ 计算向量场 $v_{t}(x_{t},t)$ 为 $t$ 时刻模型预测的向量场 $v$ 计算 $\\text{MSE}(v_{t},u_{t})$，梯度下降训练模型 简单写一个训练代码。网络结构就不写了\ndef cfm_loss(model, x1): B = x1.size(0) # Batch size of training data x1 t = torch.rand(B, device=x1.device) # U[0,1] x0 = torch.randn_like(x1) # 高斯先验 xt = (1 - t[:, None, None, None]) * x0 + t[:, None, None, None] * x1 ut = x1 - x0 # 真实速度（线性插值的导数） v = model(xt, t) return F.mse_loss(v, ut) for epoch in range(20): model.train() for x, _ in loader: x = x.to(device) loss = cfm_loss(model, x) opt.zero_grad(); loss.backward(); opt.step() print(f\u0026#34;epoch {epoch:02d} | loss {loss.item():f}\u0026#34;) 这里的细节 $t$ 是取 B 个服从 Uniform(0,1) 的数，表示均匀时间步。\nSampling # 采样的核心公式是欧拉积分\n$$ x_{t+dt}=x_{t}+v_{\\theta}(x_{t},t)*dt $$ Euler Method： # Initialize $x_0 \\sim \\mathcal{N}(0,1)$ . Set T (number of steps) and compute $dt = \\frac{1}{T}$ . For $i = 0, 1, \\ldots, T-1$ : Compute time $t_i = i \\cdot dt$ . Evaluate velocity field $v_\\theta(x_{t_i}, t_i)$ . Update $x_{t_{i+1}} = x_{t_i} + v_\\theta(x_{t_i}, t_i) \\cdot dt$. Output $x_{T}$ as the final sample. Improved Euler Method (Heun) # The Heun method uses a predictor-corrector approach:\n$$ x_{t+dt} = x_t + \\frac{1}{2} \\cdot dt \\cdot \\big( v_\\theta(x_t, t) + v_\\theta(x_{t+dt}^{\\text{pred}}, t+dt) \\big) $$where $x_{t+dt}^{\\text{pred}} = x_t + v_\\theta(x_t, t) \\cdot dt$.\nSteps:\nInitialize $x_0 \\sim \\mathcal{N}(0,1)$ . Set T (number of steps) and compute $dt = \\frac{1}{T}$ . For $i = 0, 1, \\ldots, T-1$ : Compute time $t_i = i \\cdot dt$ . Evaluate $v_1 = v_\\theta(x_{t_i}, t_i)$ . Compute predictor $x_{t_{i+1}}^{\\text{pred}} = x_{t_i} + v_1 \\cdot dt$ . Evaluate $v_2 = v_\\theta(x_{t_{i+1}}^{\\text{pred}}, t_i + dt)$ . Update $x_{t_{i+1}} = x_{t_i} + \\frac{1}{2} \\cdot dt \\cdot (v_1 + v_2)$ . Output $x_T$ as the final sample. @torch.no_grad() def sample(model, n=16, steps=60): model.eval() x = torch.randn(n, 3, 32, 32, device=device) # t=0 的高斯 t0, t1 = 0.0, 1.0 ts = torch.linspace(t0, t1, steps+1, device=device) # Heun（改进欧拉）稳定些 for i in range(steps): t = ts[i].expand(n) dt = (ts[i+1] - ts[i]).item() v1 = model(x, t) # k1 x_pred = x + dt * v1 v2 = model(x_pred, ts[i+1].expand(n)) # k2 x = x + 0.5 * dt * (v1 + v2) return torch.clamp(x, -1, 1) ","date":"13 August 2025","externalUrl":null,"permalink":"/posts/ai/cv/cornerstone/flow-matching-%E7%9A%84%E5%9F%BA%E6%9C%AC%E7%90%86%E8%A7%A3/","section":"Posts","summary":"","title":"Flow Matching 的基本理解","type":"posts"},{"content":"","date":"11 August 2025","externalUrl":null,"permalink":"/tags/ddpm/","section":"Tags","summary":"","title":"DDPM","type":"tags"},{"content":" DDPM Key Points # 参考资料 # 生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼 - 科学空间|Scientific Spaces 扩散模型(Diffusion Model)详解：直观理解、数学原理、PyTorch 实现 | 周弈帆的博客 苏神写的无疑是最容易理解的（但不是原文作者的推导方法），周弈帆的博客最贴近原作，还有代码讲解。这应该是我读过的写得最清楚的两篇了。\n这个视频也令人豁然开朗：\n原代码在：GitHub - hojonathanho/diffusion: Denoising Diffusion Probabilistic Models\nDDPM # Perturbation Process # 加噪 Perturbation，是从原图 $x_{0}$ 逐步加噪到高斯噪声 $x_{T}$：\n$$ x_{t}=\\sqrt{ \\beta_{t} } \\epsilon+\\sqrt{ 1-\\beta_{t} } x_{t-1} \\tag{1} $$$\\beta_{t}$ 随时间 $t$ 增长，betas = np.linearspace(0.0001, 0.02, 1000) 也就是从 min=0.0001 到 max=0.02 均匀生成 1000 个 tensor，导致加的噪声越来越大，均值缩放程度越来越小。 $\\alpha_{t}=1-\\beta_{t}$。alphas = 1.0 - betas\n加的噪声 noise = torch.randn_like(x) 与 $x$ 的形状保持一致。\n图像像素 $x$ 是原图 [0,255] 经过映射到 [-1,1] 再加噪的。映射公式是：$x:=\\frac{x}{255}*2-1$。torchvision.transforms.ToTensor() 可以做到把图像从 [0,255] 转化为 [0,1] 的张量。\n我们可以从 $x_{0}$ 直接生成任意时间的图像 $x_{t}$:\n$$ x_{t}=\\sqrt{ 1-\\bar{\\alpha_{t}} }\\epsilon + \\sqrt{ \\bar{\\alpha_{t}} } x_{0} \\tag{2} $$我们训练的核心就是在加噪过程，基本 idea 就是用网络预测一个 $\\epsilon_{\\theta}$ 去逼近加噪过程的噪声 $\\epsilon$。\nDenoise Process # 这个和采样过程关系比较大。\n去噪过程相反。从一张高斯分布的图片 $x_{T}$ 到高清原图 $x_{0}$，完成生成过程。\nDDPM 不是去直接预测原图，而是预测一个可以去除的噪声 $\\epsilon_{\\theta}$，通过以下公式：\n$$ x_{t-1}=\\frac{1}{\\sqrt{ \\alpha_{t} }}\\left( x_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{ 1-\\bar{\\alpha_{t}} }}\\epsilon_{\\theta} \\right)+\\sigma_{t}z \\tag{3} $$关键的就是这个可去除噪声 $\\epsilon_{\\theta}$，由神经网络预测。输入是 $t$ 时刻的图像 $x_{t}$ 和编码的时间 $t$ 信息，经过 UNet 网络预测。$z \\in N(0,1)$\n这个式子在苏剑林的博客 生成扩散模型漫谈（一）：DDPM = 拆楼 + 建楼 - 科学空间|Scientific Spaces 里推导得比较好。他注意到公式 (1) 可以用\n$$ x_{t-1}=\\frac{1}{\\sqrt{ \\alpha_{t} }}x_{t}-\\sqrt{ \\beta_{t} }\\epsilon \\tag 4 $$表示，所以先假设了去噪过程 $x_{t}$ 和 $\\epsilon$ 之前的系数，然后解方程推出来的。\nTraining # 与加噪过程紧密相关，基本 idea 就是用 UNet 网络预测一个 $\\epsilon_{\\theta}$ 去逼近每一个加噪过程的噪声 $\\epsilon$。\n$x_{0} \\sim q(x_{0})$，意思是从数据集中采样一张原图 $x_{0}$ $t \\sim \\text{Uniform}({1,\\dots T})$，Uniform 是均匀分布，意思是选定一个时间步 $t$ $\\epsilon \\sim N(0,1)$，从高斯分布中采样出该时间步 $t$ 加的噪声。这个 $\\epsilon$ 是 Ground Truth 预测该步加噪后的图片 $x_{t}=\\sqrt{ 1-\\bar{\\alpha_{t}} }\\epsilon + \\sqrt{ \\bar{\\alpha_{t}} } x_{0} \\tag{2}$。$\\alpha_{t}$ 是之前通过假设 $\\beta_{t}$ 得出的常数 用 UNet 预测噪声。输入 encoded $t$ 和在第 4 步获得的 $t$ 时刻的图像 $x_{t}$，预测一个噪声 $\\epsilon_{\\theta}(x_{t}, t)=\\epsilon_{\\theta}(\\sqrt{ 1-\\bar{\\alpha_{t}} }\\epsilon + \\sqrt{ \\bar{\\alpha_{t}} } x_{0},t)$。这个 $\\epsilon_{\\theta}$ 是模型预测值，需要逼近 Ground Truth 计算梯度 $\\nabla_{\\theta}|| \\epsilon - \\epsilon_{\\theta}(\\sqrt{ 1-\\bar{\\alpha_{t}} }\\epsilon + \\sqrt{ \\bar{\\alpha_{t}} } x_{0}) ||_{2}^2$ 重复以上过程直至收敛 其实核心思想就在于，我们通过公式可以直接从原图 $x_{0}$ 加一个高斯噪声 $\\epsilon$，到 $x_{t}$，然后我们只需要得知第 $t$ 步加噪多少就可以了——这一部分直接交给神经网络去拟合。如果我们能预测出第 t 步加的噪声，那么我们就能一步一步反向去噪得到原图。这就是采样过程。\n最后这个损失函数推导还挺难的。但是很符合直觉。\nSampling # 说是采样，其实就是推理过程。基本 idea 是我们已经有可以推理出每一个时间 t 下，加了多少噪声的模型 $\\epsilon_{\\theta}(x_{t},t)$ 了，那我们用公式 (3) 反向推回去就行。\n$x_{t}=N(0,1)$。这是推理的起点。在加噪之后获得一张纯高斯噪声图片 $x_{t}$。 for t = T, …, 1 循环以下过程 先采样 $z \\sim N(0,1) \\text{ for t\u0026gt;1 , else }z=0$。这个是公式 (3) 里反向去噪用到的高斯 perturbation $x_{t-1}=\\frac{1}{\\sqrt{ \\alpha_{t} }}\\left( x_{t}-\\frac{1-\\alpha_{t}}{\\sqrt{ 1-\\bar{\\alpha_{t}} }}\\epsilon_{\\theta}(x_{t},t) \\right)+\\sigma_{t}z$，利用公式 (3) 递推去噪的图片 返回去噪的图片 $x_{0}$ 再次提醒我们的 UNet 网络预测的是噪声，输入是图像 $x_{t}$ 以及编码的时间信息 $t$，输出是 $\\epsilon_{\\theta}(x_{t},t)$\n","date":"11 August 2025","externalUrl":null,"permalink":"/posts/ai/cv/cornerstone/diffusion-model/","section":"Posts","summary":"","title":"Diffusion Model","type":"posts"},{"content":"","date":"5 August 2025","externalUrl":null,"permalink":"/tags/langevin/","section":"Tags","summary":"","title":"Langevin","type":"tags"},{"content":"","date":"5 August 2025","externalUrl":null,"permalink":"/tags/mcmc/","section":"Tags","summary":"","title":"MCMC","type":"tags"},{"content":" MCMC # 参考： https://zhuanlan.zhihu.com/p/37121528 https://medium.com/@WeiranLin/acceptance-rejection-sampling-method-illustrated-with-python-0552c0eb27d2 https://chatgpt.com/share/688ce531-d530-8011-9afc-b76d072f1215\n本文假设你已经了解了马尔可夫链的基本定义、平稳分布的含义。\n动机 # 我在学这个算法之前，参考了许多网上的教程，结果上来就是数学公式，看到一半还不知道自己在解决什么样的问题。这部分把要解决什么样的问题这件事情说清楚。\n我们要知道，现实世界中的很多概率分布是不太好估计的，并非所有概率分布都长得像高斯分布那样优雅。比如下面的分布：\nMade by Geogebra https://www.geogebra.org/calculator/qfjrjj6v. Example from FunInCode, Bilibili\n绿色线这个关于 $x$ 的分布，就问你不看表达式的情况下怎么求它的分布 $P(X)$？求不了一点吧。\n上面这种纯恶心人的分布还是一维的，更别提现实生活中更复杂的分布，例如生成式模型任务让你求一张图片 256 个像素点的联合分布 $P(x_1,x_2,…,x_{256})$ 🤮。我们不得不找一种“用数据去估计分布”的方法。\n但其实，我们也没有必要把分布的函数形式给求出来。很多分布是没有好看的函数形式的，也可能根本求不出来。我们想要的只是“从分布中采样”这么一件事情。我们可以不知道上面绿色这个分布的形式，但却可以从绿色这个分布中 sample 出很多样本 $x_1,x_2,…,x_n$。这就很 nice！以生成式模型为例，假设我们在不知道“麦晓雯美图”分布是什么的情况下，依然可以从“麦晓雯美图”分布中采样出符合这个分布的 256 个像素点 $(x_1,x_2,…,x_{256})$，那这个生成式任务不就完成了吗？\nMCMC 采样 # 平稳分布、详细平衡条件 # 那么先哲们是如何通过马尔科夫链，去跟采样这件事情联想起来的呢？\n其实马尔可夫链本身就可以看作是对概率分布 $P$ 的建模。举个很简单的例子，我们要对北京 A、上海 B三个地方的人口密度分布进行建模。当前的概率分布为 $\\pi(A)=0.6, \\pi(B)=0.4$，并假设人口在城市间的转移概率服从马尔可夫链：\n当前城市 → 下一个城市 A B A 0.7 0.3 B 0.5 0.5 那我们想问：下一步 A 点的分布是什么？\n好算！$π(A)=π(A)⋅P(A→A)+π(B)⋅P(B→A)=0.6⋅0.7+0.4⋅0.5=0.42+0.2=0.62$\n原先的分布里 A 的概率是 0.6，现在变成了 0.62，依然不平稳。但根据遍历定理，再过几步，A 和 B 的概率分布一定可以达到平稳状态。\n从上面的例子中我们提出几个符号：\n$\\pi(x)$：表示当前在状态 x 的概率（这是你当前的分布） $P(x \\to x\u0026rsquo;)$：从状态 x 跳到状态 x′ 的转移概率 所以 $\\pi(x) P(x \\to x\u0026rsquo;)$：表示你现在在 x，然后走到 x′的整体概率流量。遍历所有能走到 $x\u0026rsquo;$ 的路，就是 $\\Sigma \\pi(x)P(x \\to x\u0026rsquo;) ,\\forall x$ ，这个式子表示下一个时间步里 $x\u0026rsquo;$ 的分布情况，如果能够与 $\\pi(x\u0026rsquo;)$——也就是当前 x’的分布相等，那么说明什么？\n说明“再走一步，分布不变”，说明我们达到了平稳分布！\n而详细平衡条件是一个更强的条件，能推出平稳分布。如果我们有从北京到上海的人流，与从上海到北京到人流相等，——也就是任意两个点之间双向的流量相等，——那么就说明系统达到平稳分布了。\n$$ \\pi(x)P(x \\to x')=\\pi(x')P(x'\\to x) $$以上就是详细平衡条件。\n从前面那个公式：\n$π(x\u0026rsquo;)=∑xπ(x)P(x→x\u0026rsquo;)\\pi(x\u0026rsquo;) = \\sum{x} \\pi(x) P(x \\to x\u0026rsquo;)$\n如果每一对 $(x, x\u0026rsquo;)$ 都满足 $\\pi(x) P(x \\to x\u0026rsquo;) = \\pi(x\u0026rsquo;) P(x\u0026rsquo; \\to x)$\n那么就可以替换右边成：\n$\\sum_{x} \\pi(x\u0026rsquo;) P(x\u0026rsquo; \\to x) = \\pi(x\u0026rsquo;) \\sum_{x} P(x\u0026rsquo; \\to x) = \\pi(x\u0026rsquo;)$（因为对马尔科夫链来说，$\\sum_{x} P(x\u0026rsquo; \\to x) = 1$）\n所以，详细平衡 ⇒ 平稳分布。\nM-H MCMC # MH 的厉害之处就是：\n通过一个简单的“接受 - 拒绝”机制，构造出满足详细平衡的马尔科夫链，从而让我们能从目标分布 $\\pi(x)$ 采样。\n基本概念有：\n🎯目标分布 $\\pi(x)$。我们的目标分布 ${\\pi(x)}$ 可以是一个很复杂的分布，不需要知道归一化常数 $Z$。 ❔提议分布 $q(x\u0026rsquo;|x)$。表示当前状态 x 下，打算怎么样跳到 x’。 有了提议分布，我们却并不打算接受它。我们以概率 $\\alpha=min(1, \\frac{\\pi(x\u0026rsquo;)q(x|x\u0026rsquo;)}{\\pi(x)q(x\u0026rsquo;|x)})$ 的概率接受它。 很懵，我来告诉你为什么这么做。\n现在我们的转移概率变成了 $P(x \\to x\u0026rsquo;)=q(x\u0026rsquo;|x)\\alpha$，乘上当前的状态 $\\pi(x)$ 就是下一个时刻从 x 到 x’的“流量”：\n$π(x)P(x→x\u0026rsquo;)=π(x)q(x\u0026rsquo;∣x)α(x,x\u0026rsquo;)=min(π(x)q(x\u0026rsquo;∣x),π(x\u0026rsquo;)q(x∣x\u0026rsquo;))$\n观察到这个式子是对称的！也就是说下一个时刻从 x’到 x 的“流量”，依然等于右式。想想之前“详细平稳”的条件——任意两个点之间双向的流量相等，我们成功证明了按照 M-H 方法，系统达到了详细平衡，也达到了平稳分布。\nLangevin MCMC # 人工智能专业的学生表示 Langevin 方程懂不了一点。我直接复制 GPT 了：\n朗之万动力学（Langevin Dynamics）采样是非常有趣且强大的采样方法，尤其适合于连续分布和物理模拟。我们可以将它视为一种基于物理系统的马尔科夫链蒙特卡洛（MCMC）方法，它使用了梯度信息来引导采样，从而能够更加高效地在复杂分布中采样。\n🧠 朗之万动力学采样的基本思路 # 朗之万动力学采样（Langevin sampling）是通过模拟物理系统中的粒子运动来获得目标分布的样本。这个过程受到以下两方面的影响：\n势能（Potential energy）：它是目标分布的对数值，用来定义粒子的行为。 噪声：模拟粒子的随机运动，用来引入随机性。 这类似于温度控制的物理过程，其中粒子在潜在势场中受力，并且每次迭代都受到随机扰动。\n🔬 朗之万方程（Langevin Equation） # 在经典物理中，朗之万方程描述了粒子如何在势能场中运动。其数学表达式如下：\n$$ \\frac{dx}{dt} = - \\nabla U(x) + \\sqrt{2 \\gamma} \\, \\eta(t) $$其中：\nx 是粒子的状态（类似于 MCMC 中的采样点）， U(x) 是势能（在采样中，它通常是目标分布的负对数）， γ 是摩擦系数（决定粒子运动的阻力）， η(t) 是一个高斯白噪声，代表随机扰动。 🧑‍🔬 离散化的朗之万动力学采样 # 由于朗之万方程是连续的，我们通常需要将其离散化以便在计算机上实现。在离散化时，我们使用欧拉方法：\n$$ x_{t+1}=x_t−ϵ∇U(x_t)+2ϵγ ξx_{t+1} = x_t - \\epsilon \\nabla U(x_t) + \\sqrt{2 \\epsilon \\gamma} \\, \\xi_t $$其中：\n$\\epsilon$ 是步长（控制每一步的更新幅度）， $\\nabla U(x_t)$ 是目标分布（势能）的梯度，似乎只有这个是比较重要的 $\\xi_t$ 是标准正态分布的随机噪声（每一步的随机扰动）。 在 Energy-based model 的语境下：\n$$ p(x)=\\frac{e^{-U(x)}}{Z} $$能量\n$$ U(x)=-\\log p(x) $$我们已知条件是 score-function\n$$ s_\\theta(x) \\approx \\nabla_x \\log p(x) $$因此在 Langevin MCMC 中\n$$ \\nabla_x U(x_t)=-\\nabla_x \\log p(x) $$对应了“概率往梯度上升的方向走”。\n🎯 步骤概述：朗之万采样算法 # 初始化：选择一个起始点 $x_0$。 计算梯度：计算目标分布的梯度 $\\nabla U(x_t)$。 更新状态：根据离散化的朗之万方程更新状态 $x_{t+1}$。 重复：重复多次，直到收集足够的样本。 🧑‍💻 代码实现（伪代码示例） # import numpy as np import matplotlib.pyplot as plt ## 目标分布：标准正态分布的负对数 def target_distribution(x): return 0.5 * x**2 ## U(x) = (1/2) * x^2 ## 梯度：目标分布的梯度 def grad_target_distribution(x): return x ## U\u0026#39;(x) = x ## 朗之万动力学采样 def langevin_dynamics(n_samples, step_size=0.1, gamma=0.1): ## 初始状态 x = 0 samples = [x] for _ in range(n_samples - 1): ## 计算梯度 grad_U = grad_target_distribution(x) ## 添加噪声（高斯扰动） noise = np.random.normal(0, np.sqrt(2 * step_size * gamma)) ## 更新状态 x = x - step_size * grad_U + noise ## 记录样本 samples.append(x) return np.array(samples) ## 采样 10000 次 samples = langevin_dynamics(10000) ## 绘制直方图 plt.hist(samples, bins=50, density=True, alpha=0.6, color=\u0026#39;b\u0026#39;) x = np.linspace(-4, 4, 100) plt.plot(x, np.exp(-target_distribution(x)), \u0026#39;r\u0026#39;, lw=2) ## 目标分布的密度函数 plt.title(\u0026#39;Langevin Dynamics Sampling\u0026#39;) plt.show() 📚 解释代码： # 目标分布：我们选了一个简单的标准正态分布的负对数（势能）作为目标分布 $U(x)。$ 这其实是 $\\pi(x) = \\mathcal{N}(0, 1)$ 的负对数。 梯度计算：计算 $U(x)$ 的梯度（对于 $U(x) = \\frac{1}{2} x^2$ 来说，梯度就是 $\\nabla U(x) = x$）。 更新状态：每次更新状态时，除了梯度项外，还加了一个来自高斯噪声的扰动项，确保状态更新是随机的。 绘制直方图：运行采样并绘制直方图，看看朗之万采样生成的样本是否接近目标分布。 🎯 优点与应用 # 高效采样：朗之万采样可以高效地在复杂的目标分布中采样，尤其适用于有梯度信息的情形。 物理模型模拟：广泛应用于分子动力学模拟、粒子系统、统计物理等领域。 与 MH 对比：相较于 Metropolis-Hastings，朗之万采样通过使用梯度信息，可以在某些情况下更快收敛，并且更好地探索复杂的多峰分布。 ","date":"5 August 2025","externalUrl":null,"permalink":"/posts/ai/cv/cornerstone/mcmc-markov-chain-monte-carlo/","section":"Posts","summary":"","title":"MCMC (Markov Chain Monte Carlo)","type":"posts"},{"content":"","date":"5 August 2025","externalUrl":null,"permalink":"/tags/dev/","section":"Tags","summary":"","title":"Dev","type":"tags"},{"content":" 训练常用命令 # TL;DR # 运行完 shutdown 的终极写法\n直接把下面的内容保存到 scripts/train.sh 里，然后 tmux 里 bash scripts/train.sh 执行，应该是最方便的做法\ncommand 2\u0026gt;\u0026amp;1 | tee train_$(date +%Y%m%d_%H%M%S).log echo \u0026#34;Training completed. Shutdown in 1 min\u0026#34; sleep 60s shutdown 如果只需要年月日（train_2025-11-17.log）并且在终端执行，shutdown\nset -o pipefail command 2\u0026gt;\u0026amp;1 | tee train_$(date +%F).log \u0026amp;\u0026amp; shutdown +1 # shutdown only when success in 1 min command 2\u0026gt;\u0026amp;1 | tee train_$(date +%F).log ; shutdown +1 # shutdown whatever in 1 min 按需把 \u0026amp;\u0026amp; 换成 ; 前者只有在命令成功才会 shutdown\n取消 shutdown：\nshutdown -c # c means cancle 后台运行和持久化 # Nohup # 最方便的命令，配合 tail 或者 cat 使用，适合我某天不想折腾的场景。\nnohup command \u0026gt; train_$(date +%Y%m%d_%H%M%S).log 2\u0026gt;\u0026amp;1 \u0026amp;\u0026amp; shutdown \u0026amp; # 然后用tail或者cat查看文件 缺点很明显，用 jobs 命令 kill 进程的时候通常不知道 kill 哪个，特别是跑多命令的情况下。并且跑的时候也不能实时看不到输出。这就不如 tmux 了。\nTee # 作用\u0026amp;需求 # 👉 把标准输入的内容同时输出到屏幕（stdout）和文件。\n对于那种初级的、跑一次就不用管的、但是要持久化的命令——比如在服务器上起一个后端，后续只需要看看 log 的服务，用 nohup 就可以最简单地解决，只需要时不时登上去用 tail 看看跑的怎么样、用 scp 下载 log debug 就行。\n但是深度学习的需求是需要长时间盯着屏幕看输出，又还不能一直看（没那么多时间），跑完又得立刻关机，这时候最好的解决方式就是用 tmux 加 tee。\n用法 # 最好是 tmux 起一个 session 之后：\ncommand | tee out.log 这样 tmux 里也能看到输出，同时输出还会被 file.log 记录下来。（此时要点名 tqdm 库，它的进度条输出到文件的样子又臭又长，但是从终端里看的效果就会好很多）。\ntee 只会重定向标准输出 stdout，而不会重定向错误输出 stderr 。而 python logging 用的是 stderr，所以要是想看到日志，需要这么写：\ncommand 2\u0026gt;\u0026amp;1 | tee out.log pipefail 的作用：如果想要 shutdown set -o pipefail # 如果不加 set -o pipefail，以下命令会直接 shutdown command | tee train.log \u0026amp;\u0026amp; shutdown command | tee train.log ; shutdown 因为 command | tee train.log \u0026amp;\u0026amp; shutdown 里的 \u0026amp;\u0026amp; 只看管道命令的退出码，而 管道命令的退出码默认由最右边的进程决定。 tee 本身几乎永远返回 0，所以即使 command 里的 Python 抛了异常，整条管道仍然被 shell 视为“成功”，shutdown 就被执行了。\nTmux # https://www.ruanyifeng.com/blog/2019/10/tmux.html\n极简流程 # 新建会话 tmux new -s my_session。或者直接 tmux 进入一个从 0 开始自然编号的 session。 在 Tmux 窗口运行所需的程序。 按下快捷键 Ctrl+b d 将会话分离。 下次使用时，重新连接到会话 tmux a -t my_session 或者 tmux attach-session -t my_session。或者直接 tmux a。 支持鼠标滚动 # ctrl+b 进入命令面板，在命令行处输入 : ，然后输入 set -g mouse on 按回车即可。但是我感觉 Ctrl+b [：进入 vi 模式会更舒适一点。\n保存输出 # tmux capture-pane -p -S - -E - \u0026gt; output.txt S -：表示从缓冲区的最开始（最顶端）开始捕获。 E -：表示捕获到缓冲区的末尾（最底端）。如果输出太多，且缓冲区设置有限，早期的输出会被丢弃，不会在这里捕获到。 p：打印捕获内容到标准输出，配合重定向保存文件。 使用 tmux set-option -g history-limit 50000 把缓存区历史记录增大到 50000 条\nSwitch Sessions (Collaborated with nvim) # ctrl+b, s quickly switch between opened sessions.\ntmux 里使用 nvim 似乎会有颜色和 nerd-font 的偏差…解决办法是让 tmux 把 24 位色透传给 Neovim。在 ~/.tmux.conf 里：\nset -g default-terminal \u0026#34;tmux-256color\u0026#34; # 不要写 screen-256color set -as terminal-features \u0026#39;,*:RGB\u0026#39; # 2.9+ 用 RGB；老版本写 \u0026#39;,*:Tc\u0026#39; set -g window-active-style \u0026#39;fg=default,bg=default\u0026#39; 不想折腾了，就不要在 tmux 里开 nvim 就行。在主程序里使用 nvim，然后 ctrl z 进入 bg，再去 tmux 里执行命令，最后回到前台用 fg 命令就行。\n其他常用命令\u0026amp;快捷键 # tmux 快速进入一个 session。从 0 开始编号。 tmux ls 列出所有 session 终止当前窗格的命令： ctrl+b ， x Ctrl+b c：创建一个新窗口，状态栏会显示多个窗口的信息。 Ctrl+b p：切换到上一个窗口（按照状态栏上的顺序）。 Ctrl+b n：切换到下一个窗口。 Ctrl+b \u0026lt;number\u0026gt;：切换到指定编号的窗口，其中的 \u0026lt;number\u0026gt; 是状态栏上的窗口编号。 Ctrl+b w：从列表中选择窗口。 Ctrl+b ,：窗口重命名。 Echo # 别的没啥说的，今天发现 echo -e \u0026quot;\\a\\a\u0026quot; 可以让电脑蜂鸣两声（但在 Alacritty ssh 上无效）。\n\\a 是 ASCII 的 BEL 字符（0x07）。 -e 让 echo 解释转义序列；两个 \\a 就是连续两次蜂鸣信号。 Top # 查看系统占用的命令。可以用来查看一下当前的命令有没有跑完。\n传输和下载 # Ssh # 我为什么要说这个呢？因为我最近才发现 ssh -A 参数含义是 ForwardAgent，可以把本地的 sshkey 转发到服务器上！从而用 git 操作的时候就不需要认证了！那这我还用个毛线的 jupyterlab 啊，还是 vscode 好用。\nCurl # curl -LO -C - \u0026#34;https://example.com/path/file.bin\u0026#34; -L：遇到 30x 重定向时跟着跳转（很多下载链接会 302）。 -o 保存文件名：把内容写进文件，而不是 stdout；文件名自己起，后缀保持 .bin、.zip、.jpg 等原始格式即可。 -C -（可选）：断点续传，网络中断后重新跑同一条命令可接着下。 -O：如果 URL 里包含文件名则自动识别，如果没包含会 404。 Scp # 好处在于 windows 上也自带这个命令，而且很简单，只需记住 -r 参数就可以了。\n坏处是小文件特别多的话比较慢。这种情况下建议主用 rysnc 。\n为什么最好不要用 git 呢？首先自己写的 private 仓库代码用 git 不好在服务器上同步，其次 git lfs 也会占用大空间（ du -h ./ 查看），再者部署用 git 也实在不优雅。一般部署是用 scp 传二进制或者 rsync 传 python 这种零散脚本。\n递归复制目录：\nscp -r my_directory user@remote_host:/home/user/directory 复制本地的文件到远程。反之从远程到本地的话就改一改。\n不需要对文件在远程再命名 ( •̀ ω •́ ) 是直接就放进对应目录里\nscp -P 35394 *pt user@remote.com:/root/models/ ## 本地的*.pt文件，注意不带/的话会直接重命名为models！ scp -P 35394 model1.pt model2.pt user@remote.com:/root/models/ ## 可以拷贝多个文件 常用参数 rpvC ：\nr：递归复制整个目录。 P：指定远程主机的 SSH 端口号（默认是 22）。注意， P 是大写 p：保留文件的修改时间、访问时间和权限。 v：显示详细的调试信息，有助于排查问题。 C：启用压缩，可以加快传输速度。 Rsync # 这个和 scp 命令起到的作用差不多，但是支持断点续传、增量传输。但是这个命令 windows 上没有。\n如果 ssh 命令有附加的参数，则必须使用 -e 参数指定所要执行的 SSH 命令。\n最终版命令 # 一般最常用的选项组合 -avzP 来进行传输。支持同步增量传输、改端口、忽略隐藏文件：\nrsync -avzP -e \u0026#39;ssh -p 2234\u0026#39; --exclude=\u0026#39;.*\u0026#39; source/ user@remote_host:/destination 如果要排除一些文件夹（比如说 .venv ），用 --exclude 。\n这里有个坑 路径是自动相对于传输目录的正则，下面的例子如果写 --exclude='./models 就会完全匹配不上。\n## 支持通配符，用于删除mac finder下一些不可名状的小东西和.venv之伦 rsync -avzP --exclude=\u0026#39;.*\u0026#39; --exlude=\u0026#39;models*\u0026#39; /local/path/ user@remote:/remote/path/ 参数 # a、-archive 参数表示存档模式，保存所有的元数据，比如修改时间（modification time）、权限、所有者等，并且软链接也会同步过去。 -append 参数指定文件接着上次中断的地方，继续传输。 -append-verify 参数跟 -append 参数类似，但会对传输完成后的文件进行一次校验。如果校验失败，将重新发送整个文件。 b、-backup 参数指定在删除或更新目标目录已经存在的文件时，将该文件更名后进行备份，默认行为是删除。更名规则是添加由 -suffix 参数指定的文件后缀名，默认是 ~。 -backup-dir 参数指定文件备份时存放的目录，比如 -backup-dir=/path/to/backups。 -bwlimit 参数指定带宽限制，默认单位是 KB/s，比如 -bwlimit=100。 c、-checksum 参数改变 rsync 的校验方式。默认情况下，rsync 只检查文件的大小和最后修改日期是否发生变化，如果发生变化，就重新传输；使用这个参数以后，则通过判断文件内容的校验和，决定是否重新传输。 -delete 参数删除只存在于目标目录、不存在于源目标的文件，即保证目标目录是源目标的镜像。（有风险！模型训练完，如果加这个参数的话直接没了） e 参数指定使用 SSH 协议传输数据。 -exclude 参数指定排除不进行同步的文件，比如 -exclude=\u0026quot;*.iso\u0026quot;。 -exclude-from 参数指定一个本地文件，里面是需要排除的文件模式，每个模式一行。 -existing、-ignore-non-existing 参数表示不同步目标目录中不存在的文件和目录。 h 参数表示以人类可读的格式输出。 h、-help 参数返回帮助信息。 i 参数表示输出源目录与目标目录之间文件差异的详细情况。 -ignore-existing 参数表示只要该文件在目标目录中已经存在，就跳过去，不再同步这些文件。 -include 参数指定同步时要包括的文件，一般与 -exclude 结合使用。 -link-dest 参数指定增量备份的基准目录。 m 参数指定不同步空目录。 -max-size 参数设置传输的最大文件的大小限制，比如不超过 200KB（-max-size='200k'）。 -min-size 参数设置传输的最小文件的大小限制，比如不小于 10KB（-min-size=10k）。 n 参数或 -dry-run 参数模拟将要执行的操作，而并不真的执行。配合 v 参数使用，可以看到哪些内容会被同步过去。 P 参数是 -progress 和 -partial 这两个参数的结合。 -partial 参数允许恢复中断的传输。不使用该参数时，rsync 会删除传输到一半被打断的文件；使用该参数后，传输到一半的文件也会同步到目标目录，下次同步时再恢复中断的传输。一般需要与 -append 或 -append-verify 配合使用。 -partial-dir 参数指定将传输到一半的文件保存到一个临时目录，比如 -partial-dir=.rsync-partial。一般需要与 -append 或 -append-verify 配合使用。 -progress 参数表示显示进展。 r 参数表示递归，即包含子目录。 -remove-source-files 参数表示传输成功后，删除发送方的文件。 -size-only 参数表示只同步大小有变化的文件，不考虑文件修改时间的差异。 -suffix 参数指定文件名备份时，对文件名添加的后缀，默认是 ~。 u、-update 参数表示同步时跳过目标目录中修改时间更新的文件，即不同步这些有更新的时间戳的文件。 v 参数表示输出细节。vv 表示输出更详细的信息，vvv 表示输出最详细的信息。 -version 参数返回 rsync 的版本。 z 参数指定同步时压缩数据。 --delete 删除本机没有，远程有的文件。 文件系统和压缩 # Ln # 创建链接。\n一般用 rsync 命令把代码文件传到 ~ 目录下，然后用 scp 或 jupyter-lab 或 oss 或其他随便什么东西，把模型文件传到 /hy-tmp 下，最后用软链接结合它们。\n比如恒源云， /hy-tmp 文件夹是 SSD，读写速度最快，那么就需要把当前文件夹下的数据集先移动到 /hy-tmp 再创建软连接：\nmv -p ./dataset /hy-tmp/niyuta/dataset \u0026amp;\u0026amp; ln -s /hy-tmp/niyuta/dataset dataset 这里也有坑 如果后面 ln 写的是 ln -s /hy-tmp/niyuta/dataset ./dataset 就会报错本地没有这个文件夹。其实仔细想想就能明白， dataset 是一个符号而已，将其指派为文件夹显然不对。\n突然发现如果不指定 ln -s 的软链接文件名，可以自动在当前目录创建一个同名的：\nln -s /my_dataset 上面的命令直接会在当前目录创建一个名为 dataset 的软链接。\nTar # 解压 # tar -xvzf file.tar.gz -x 解包（extract） -v 显示过程（verbose，可省略） -z 经过 gzip 压缩 -f 指定文件名 tar -xvzf file.tar.gz -C /path/to/outdir # 指定目录 压缩 # tar -cvzf archive.tar.gz dir1 file2 … 阿里源 # Pip 或临时使用 # 加参数 \u0026ndash;index-url 或 -i\n-i http://mirrors.aliyun.com/pypi/simple 实测好像阿里源卡住的概率小。\nAstral Uv # 在 ~/.config/uv/uv.toml 或者 /etc/uv/uv.toml 填写下面的内容：\n[[index]] url = \u0026#34;http://mirrors.aliyun.com/pypi/simple\u0026#34; default = true ","date":"5 August 2025","externalUrl":null,"permalink":"/posts/ai/engineer/%E8%AE%AD%E7%BB%83%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4/","section":"Posts","summary":"","title":"训练常用命令","type":"posts"},{"content":" Score Matching # 我觉得 Score matching by Andy Jones 说得挺清楚了，所以这一篇笔记主要是回忆性质，记下几个 key point 和 key idea。\nScore-matching 要解决的问题是？ 如何理解 Score 函数？Score 函数是如何解决 normalizing constant 的问题的？ 如何衡量两个分布的梯度的差距？为什么用 Fisher 散度？ 为什么涉及到真实分布 $p_d(x)$ 的就不好求？ 🙋什么是 Score Matching？ # Score Matching Score Matching 是一种用于拟合统计模型的方法，特别适用于处理不可计算归一化常数（intractable normalizing constants）的模型。在机器学习中，当模型的似然函数复杂且难以归一化时（例如在能量基模型（EBMs）、生成对抗网络（GANs）或变分自编码器（VAEs 中），Score Matching 提供了一种绕过归一化常数的方法来优化模型参数。\n假设我们有一组观测数据 $x_1, \\dots, x_n$，这些数据服从未知的真实分布 $p_d(x)$。我们希望用一个参数化的模型 model 分布 $p_m(x; \\theta)$ 来近似 distribution $p_d(x)$，其中 $\\theta$ 是模型参数。目标是找到合适的 $\\theta$，使 $p_m(x; \\theta)$ 尽可能接近 $p_d(x)$。\n在最大似然估计（MLE）中，我们通常通过最大化数据的对数似然来优化 $\\theta$：\n$$ \\widehat{\\theta}_{MLE} = argmax_{\\theta} \\log p_m(x; \\theta). $$模型的概率密度函数通常可以写成未归一化的密度 $\\widetilde{p}(x; \\theta)$ 和归一化常数 $Z_\\theta$ 的形式：\n$$ p_m(x; \\theta) = \\frac{\\widetilde{p}(x; \\theta)}{Z_\\theta}, \\quad Z_\\theta = \\int_{\\mathcal{X}} \\widetilde{p}(x; \\theta) , dx. $$这里的 $Z_\\theta$ 是一个 normalizing constant，通常在复杂模型中难以计算（即不可解，intractable）。Score Matching 的核心思想是通过避免直接计算 $Z_\\theta$，来解决这一问题。\n我觉得这里完全有必要说一下：难在哪儿？为什么不能求出 $p_d(x)$？ Note 因为真实分布只有样本，没有分布，我们可以假设模型分布 $p_m$ 为高斯啦学生分布啦等等，但是真实分布通常有可能是高斯混合模型，很难搞。所以我们得想办法消除 $p_d(x)$ 这一项。在后文中还会出现一次 $p_{m}$ 项，留意之。\n💡Score Matching 的核心思想 # 其实我们如果注意到，对上面的 model 分布 p 对 x 求梯度，那么 Z 这一项就会消失（因为参数里没有 x）。\n在 Score Matching 中，==score 函数==是指对数似然函数关于数据 $x$ 的梯度：\n$$ s_{\\theta}=\\nabla_x \\log p_m(x; \\theta). $$将其展开，我们可以看到归一化常数的优势：\n$$ \\nabla_x \\log p_m(x; \\theta) = \\nabla_x \\log \\widetilde{p}_m(x; \\theta) - \\nabla_x \\log Z_\\theta. $$由于 $Z_\\theta$ 不依赖于 $x$，其梯度 $\\nabla_x \\log Z_\\theta = 0$，因此：\n$$ \\nabla_x \\log p_m(x; \\theta) = \\nabla_x \\log \\widetilde{p}_m(x; \\theta). $$Normalizing constant Z 消失了！那么 Score matching 的核心思想变呼之欲出：如果建模分布 $p_m$ 与原始分布 $p_d$ 相似，那么他们的梯度也应该相似。最后顶多差一个偏移而已。那么我们不求（或者以后再想办法求）$p(x)$，而是去求 $p_{x}$ 对数的梯度（Score-function），让 score-function 尽可能逼近真实数据的对数梯度。这个就是 Score-matching 方法。\n🎯Score Matching 的目标 # Score Matching 的目标是最小化模型分布的 score 函数与真实数据分布的 score 函数之间的 Fisher 散度（Fisher Divergence）：\n$$ \\widehat{\\theta}_{SM} = argmin_{\\theta} D_F(p_d, p_m) = argmin_{\\theta} \\frac{1}{2} \\mathbb{E}_{p_d} \\left[ | \\nabla_x \\log p_d(x) - \\nabla_x \\log p_m(x; \\theta) |_2^2 \\right]. $$ 这是因为只有 fisher 散度可以跟梯度联系起来，而 KL 散度是做不到的。 但到了这里还是有 $p_d(x)$ 项，还是不好求。所以自然地想到下一步要怎么做。\n↻绕过归一化常数和数据分布 # 展开 Fisher 散度： $$ \\frac{1}{2} | \\nabla_x \\log p_d(x) - \\nabla_x \\log p_m(x; \\theta) |_2^2 = \\frac{1}{2} (\\nabla_x \\log p_d(x))^2 - \\nabla_x \\log p_m(x; \\theta) \\nabla_x \\log p_d(x) + \\frac{1}{2} (\\nabla_x \\log p_m(x; \\theta))^2. $$ 第一项 $\\frac{1}{2} (\\nabla_x \\log p_d(x))^2$ 是常数项，不依赖 $\\theta$，不影响优化 $\\theta$，可以忽略。 第三项 $\\frac{1}{2} (\\nabla_x \\log p_m(x; \\theta))^2$ 可以通过数据样本直接估计，因为它不依赖 $p_d(x)$。 处理交叉项： $$ \\mathbb{E}_{p_d} \\left[ -\\nabla_x \\log p_m(x; \\theta) \\nabla_x \\log p_d(x) \\right] = -\\int_{-\\infty}^{\\infty} \\nabla_x \\log p_m(x; \\theta) \\nabla_x \\log p_d(x) p_d(x) , dx. $$通过分部积分法（integration by parts）（这里很巧妙但是我不细写了），假设边界项在无穷远处消失（即 $p_d(x) \\nabla_x \\log p_m(x; \\theta) \\to 0$ 当 $|x|_2 \\to \\infty$），我们可以将交叉项转化为：\n$$ \\int_{-\\infty}^{\\infty} \\nabla_x^2 \\log p_m(x; \\theta) p_d(x) dx. $$那么问题来了：==为什么会假设边界项消失？==\n边界项消失 边界项 $p_d(x) \\nabla_x \\log p_m(x; \\theta) \\to 0$ 当 $|x|_2 \\to \\infty$ 是一个正则化条件，确保分部积分成立。直观上：\n数据分布 $p_d(x)$ 通常在无穷远处迅速衰减到零，因为实际数据集中在有限区域，尾部概率很小。例如高斯分布 $p_d(x) \\propto \\exp(-x^2 / (2\\sigma_d^2))$ 的尾部以指数速度衰减。 模型 score 函数 $\\nabla_x \\log p_m(x; \\theta)$ 通常增长较慢（例如高斯模型中为线性增长）。因此，乘积 $p_d(x) \\nabla_x \\log p_m(x; \\theta)$ 在无穷远处趋于零，因为数据分布的尾部衰减比 score 函数的增长快。 这就像在积分中，尾部贡献变得微不足道，因为数据分布在无穷远处几乎没有概率质量。 在高斯分布的例子中：\n$$ p_d(x)\\nabla_x \\log p_m(x;\\mu,\\sigma^2) \\sim \\exp\\!\\left(-\\frac{x^{2}}{2\\sigma_d^{2}}\\right)\\cdot\\frac{\\mu-x}{\\sigma^{2}} \\to 0 $$因为指数衰减比线性增长快得多。\n因为 $\\nabla_x^2 \\log p_m(x; \\theta) p_d(x) dx$ 在大于等于 2 阶情况下的其实是个 Hessian 矩阵，对角线的元素才是对 x 求二阶导，所以写成 tr 的形式 $$ \\int_{-\\infty}^{\\infty} \\nabla_x^2 \\log p_m(x; \\theta) p_d(x) dx = \\mathbb{E}_{p_d} \\left[ \\text{tr} \\left( \\nabla_x^2 \\log p_m(x; \\theta) \\right) \\right] $$所以损失函数：\n$$ D_F(p_d, p_m) \\propto L(\\theta) = \\mathbb{E}_{p_d} \\left[ \\text{tr} \\left( \\nabla_x^2 \\log p_m(x; \\theta) \\right) + \\frac{1}{2} ||\\nabla_x \\log p_m(x; \\theta)||_2^2 \\right]. $$使用数据样本 $x_1, \\dots, x_n$，目标函数可近似为：\n$$ L(\\theta) \\approx \\frac{1}{n} \\sum_{i=1}^n \\left[ \\text{tr} \\left( \\nabla_x^2 \\log p_m(x_i; \\theta) \\right) + \\frac{1}{2} |\\nabla_x \\log p_m(x_i; \\theta)|_2^2 \\right]. $$这个目标函数完全不依赖归一化常数 $Z_\\theta$ 和真实分布 $p_d(x)$，只需要模型的未归一化密度 $\\widetilde{p}_m(x; \\theta)$ 和数据样本即可。\nHyvärinen 证明，如果真实分布 $p_d(x) = p_m(x; \\theta^\\star)$ 属于模型族，则优化 $L(\\theta)$ 可找到最优参数 $\\theta^\\star$。\n只要真实分布 恰好能被模型族中的某个参数 $\\theta^\\star$ 表示出来，那么最小化得分匹配目标 $L(θ)$ 就一定能把这个 $\\theta^\\star$ 找出来。\n🤔目标函数的直观理解 # 目标函数由两部分组成：\nNorm 项：$\\frac{1}{2} |\\nabla_x \\log p_m(x_i; \\theta)|_2^2$ 表示模型 score 函数的大小。 当数据点 $x_i$ 被模型很好地解释时（即位于似然的高概率区域），score 函数的值较小（似然变化平缓）。 直观上，这个项希望模型的似然函数在数据点附近平滑。 Hessian 项：$\\text{tr} \\left( \\nabla_x^2 \\log p_m(x_i; \\theta) \\right)$ 表示对数似然的二阶导数（Hessian 矩阵的迹）。 如果数据点位于“尖锐”的局部极小值处（Hessian 迹为负且绝对值较大），说明模型对数据的解释更“独特”。 直观上，这个项倾向于选择更“尖锐”的似然函数，避免过于平坦的似然（平坦的似然意味着多种参数值都能解释数据）。 这两个项相互平衡：Norm 项倾向于平滑的似然，Hessian 项倾向于尖锐的似然，优化 $L(\\theta)$ 找到既能解释数据又具有适当曲率的模型。\n📖方法论 # 所以总结一下，最后其实很简单——甚至损失函数只和 $p_m$ 有关。假设了 $p_m$ 的分布之后：\n先求其关于训练数据的一阶导数的平方（Norm 项） 再在 Norm 项算式的基础上求其二阶导（Hessian 项） 相加，求 $argmin_{\\theta}$，就完事儿了。Score matching by Andy Jones 的最后举了一个高斯的例子，很不错。 📚 延伸阅读 # Hyvärinen (2005): 原始论文，提出得分匹配。 Song \u0026amp; Ermon (2019): 使用得分匹配进行生成建模。 Sliced Score Matching (2020): 可扩展版本，适用于高维数据。 ","date":"21 July 2025","externalUrl":null,"permalink":"/posts/ai/cv/cornerstone/score-matching-%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%8E%A8%E5%AF%BC/","section":"Posts","summary":"","title":"Score matching 的基本推导","type":"posts"},{"content":" About Me # Hi, this is Niyuta ✨\n🎓 Education # M.S. in Deep Learning @ Beihang University (BUAA) B.S. in Computer Science @ Beihang University (BUAA) 💻 Technical Stack # Languages \u0026amp; Tools:\nProficient: Python, Rust (perhaps) Familiar: Java, C#, JavaScript/TypeScript, C/C++, SQL Misc: Git, Docker, Linux, Qemu, Cloud, React, Vue, etc. 🔭 Current Interests # Machine Learning \u0026amp; Deep Learning Systems (Python 🐍) High-performance Computing (Rust 🦀) Operating Systems (Rust 🦀) Web Development (React \u0026amp; Vue \u0026amp; Go 🎉) 🎸 Beyond Code # Guitarist crafting riffs when not debugging Anime cosplayer bringing 2D to 3D Eternal student of math \u0026amp; physics ","date":"28 February 2019","externalUrl":null,"permalink":"/page/about/","section":"Pages","summary":"","title":"About","type":"page"},{"content":"","date":"28 February 2019","externalUrl":null,"permalink":"/page/","section":"Pages","summary":"","title":"Pages","type":"page"},{"content":"","externalUrl":null,"permalink":"/authors/","section":"Authors","summary":"","title":"Authors","type":"authors"},{"content":"","externalUrl":null,"permalink":"/categories/","section":"Categories","summary":"","title":"Categories","type":"categories"},{"content":"","externalUrl":null,"permalink":"/series/","section":"Series","summary":"","title":"Series","type":"series"}]